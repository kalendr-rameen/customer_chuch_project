{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Нам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Нужно постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Также необходимо проверить *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><strong>Вывод</strong></a></span></li></ul></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Исследование задачи</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Исследуем-1-ю-модель-(Логистическая-регрессия)\" data-toc-modified-id=\"Исследуем-1-ю-модель-(Логистическая-регрессия)-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Исследуем <code>1-ю модель (Логистическая регрессия)</code></a></span></li><li><span><a href=\"#Исследуем-2-ю-модель-(Дерево-решений)\" data-toc-modified-id=\"Исследуем-2-ю-модель-(Дерево-решений)-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Исследуем <code>2-ю модель (Дерево решений)</code></a></span></li><li><span><a href=\"#Исследуем-3-ю-модель-(Случайный-лес)\" data-toc-modified-id=\"Исследуем-3-ю-модель-(Случайный-лес)-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>Исследуем <code>3-ю модель (Случайный лес)</code></a></span></li></ul></li></ul></li><li><span><a href=\"#Борьба-с-дисбалансом\" data-toc-modified-id=\"Борьба-с-дисбалансом-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span><ul class=\"toc-item\"><li><span><a href=\"#Первый-метод-борьбы-с-дисбалансом-мы-выбрали-применение-параметра-class_weight='balanced'.\" data-toc-modified-id=\"Первый-метод-борьбы-с-дисбалансом-мы-выбрали-применение-параметра-class_weight='balanced'.-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Первый метод борьбы с дисбалансом мы выбрали применение параметра <code>class_weight='balanced'</code>.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Сначала-применяем-к-1-ой-модели-(логистическая-регрессия)\" data-toc-modified-id=\"Сначала-применяем-к-1-ой-модели-(логистическая-регрессия)-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Сначала применяем к <code>1-ой модели (логистическая регрессия)</code></a></span></li><li><span><a href=\"#Исследуем-2-ю-модель-(Дерево-решений)\" data-toc-modified-id=\"Исследуем-2-ю-модель-(Дерево-решений)-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Исследуем <code>2-ю модель (Дерево решений)</code></a></span></li><li><span><a href=\"#Исследуем-3-ю-модель-(Случайный-лес)\" data-toc-modified-id=\"Исследуем-3-ю-модель-(Случайный-лес)-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Исследуем <code>3-ю модель (Случайный лес)</code></a></span></li></ul></li><li><span><a href=\"#Попытаемся-применить-второй-метод-борьбы-с-дисбалансом-а-именно-upsampling,-т.е-мы-будем-искуственно-увеличивать-размер-выборки.\" data-toc-modified-id=\"Попытаемся-применить-второй-метод-борьбы-с-дисбалансом-а-именно-upsampling,-т.е-мы-будем-искуственно-увеличивать-размер-выборки.-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Попытаемся применить <strong>второй метод борьбы с дисбалансом</strong> а именно <code>upsampling</code>, т.е мы будем искуственно увеличивать размер выборки.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Теперь-применяем-полученные-данные-для-обучения-1-ой-модели-(логистическая-регрессия)\" data-toc-modified-id=\"Теперь-применяем-полученные-данные-для-обучения-1-ой-модели-(логистическая-регрессия)-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Теперь применяем полученные данные для обучения <code>1-ой модели (логистическая регрессия)</code></a></span></li><li><span><a href=\"#Теперь-применяем-полученные-данные-для-обучения-2-ой-модели-(Дерево-решений)\" data-toc-modified-id=\"Теперь-применяем-полученные-данные-для-обучения-2-ой-модели-(Дерево-решений)-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Теперь применяем полученные данные для обучения <code>2-ой модели (Дерево решений)</code></a></span></li><li><span><a href=\"#Теперь-применяем-полученные-данные-для-обучения-3-ей-модели-(Дерево-решений)\" data-toc-modified-id=\"Теперь-применяем-полученные-данные-для-обучения-3-ей-модели-(Дерево-решений)-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Теперь применяем полученные данные для обучения 3-ей модели (Дерево решений)</a></span></li></ul></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование модели</a></span></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый делом я решил избавиться от ненужных данных при обучение поскольку такие данные будут лишь успложнять построенную модель и скорее всего приведут к ошибкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           9091 non-null   float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что у нас есть пропущенные данные в колонке `tenure`, посмотрим на данные поближе чтобы понять если ли какие либо различия у этих обьектов от остальных, но прежде привёдём названия столбцов к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        creditscore           age       tenure        balance  numofproducts  \\\n",
       "count  10000.000000  10000.000000  9091.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800     4.997690   76485.889288       1.530200   \n",
       "std       96.653299     10.487806     2.894723   62397.405202       0.581654   \n",
       "min      350.000000     18.000000     0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000     2.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000     5.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000     7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000    10.000000  250898.090000       4.000000   \n",
       "\n",
       "         hascrcard  isactivemember  estimatedsalary        exited  \n",
       "count  10000.00000    10000.000000     10000.000000  10000.000000  \n",
       "mean       0.70550        0.515100    100090.239881      0.203700  \n",
       "std        0.45584        0.499797     57510.492818      0.402769  \n",
       "min        0.00000        0.000000        11.580000      0.000000  \n",
       "25%        0.00000        0.000000     51002.110000      0.000000  \n",
       "50%        1.00000        1.000000    100193.915000      0.000000  \n",
       "75%        1.00000        1.000000    149388.247500      0.000000  \n",
       "max        1.00000        1.000000    199992.480000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore geography  gender  age  tenure    balance  numofproducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "5          645     Spain    Male   44     8.0  113755.78              2   \n",
       "6          822    France    Male   50     7.0       0.00              2   \n",
       "7          376   Germany  Female   29     4.0  115046.74              4   \n",
       "8          501    France    Male   44     4.0  142051.07              2   \n",
       "9          684    France    Male   27     2.0  134603.88              1   \n",
       "\n",
       "   hascrcard  isactivemember  estimatedsalary  exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  \n",
       "5          1               0        149756.71       1  \n",
       "6          1               1         10062.80       0  \n",
       "7          1               0        119346.88       1  \n",
       "8          0               1         74940.50       0  \n",
       "9          1               1         71725.73       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>543</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26019.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>652</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114675.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>730</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85982.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>413</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6534.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>538</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108055.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27231.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     creditscore geography  gender  age  tenure    balance  numofproducts  \\\n",
       "30           591     Spain  Female   39     NaN       0.00              3   \n",
       "48           550   Germany    Male   38     NaN  103391.38              1   \n",
       "51           585   Germany    Male   36     NaN  146050.97              2   \n",
       "53           655   Germany    Male   41     NaN  125561.97              1   \n",
       "60           742   Germany    Male   35     NaN  136857.00              1   \n",
       "82           543    France  Female   36     NaN       0.00              2   \n",
       "85           652     Spain  Female   75     NaN       0.00              2   \n",
       "94           730     Spain    Male   42     NaN       0.00              2   \n",
       "99           413    France    Male   34     NaN       0.00              2   \n",
       "111          538   Germany    Male   39     NaN  108055.10              2   \n",
       "\n",
       "     hascrcard  isactivemember  estimatedsalary  exited  \n",
       "30           1               0        140469.38       1  \n",
       "48           0               1         90878.13       0  \n",
       "51           0               0         86424.57       0  \n",
       "53           0               0        164040.94       1  \n",
       "60           0               0         84509.57       0  \n",
       "82           0               0         26019.59       0  \n",
       "85           1               1        114675.75       0  \n",
       "94           0               1         85982.47       0  \n",
       "99           0               0          6534.18       0  \n",
       "111          1               0         27231.26       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>909.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>648.451045</td>\n",
       "      <td>38.647965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76117.341474</td>\n",
       "      <td>1.530253</td>\n",
       "      <td>0.710671</td>\n",
       "      <td>0.510451</td>\n",
       "      <td>99180.389373</td>\n",
       "      <td>0.201320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>99.079381</td>\n",
       "      <td>9.785438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63105.690715</td>\n",
       "      <td>0.588452</td>\n",
       "      <td>0.453701</td>\n",
       "      <td>0.500166</td>\n",
       "      <td>56378.063765</td>\n",
       "      <td>0.401207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>359.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.670000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>580.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49872.330000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>647.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96674.550000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99444.020000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128554.980000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>145759.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206663.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199390.450000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       creditscore         age  tenure        balance  numofproducts  \\\n",
       "count   909.000000  909.000000     0.0     909.000000     909.000000   \n",
       "mean    648.451045   38.647965     NaN   76117.341474       1.530253   \n",
       "std      99.079381    9.785438     NaN   63105.690715       0.588452   \n",
       "min     359.000000   18.000000     NaN       0.000000       1.000000   \n",
       "25%     580.000000   32.000000     NaN       0.000000       1.000000   \n",
       "50%     647.000000   37.000000     NaN   96674.550000       1.000000   \n",
       "75%     718.000000   43.000000     NaN  128554.980000       2.000000   \n",
       "max     850.000000   92.000000     NaN  206663.750000       4.000000   \n",
       "\n",
       "        hascrcard  isactivemember  estimatedsalary      exited  \n",
       "count  909.000000      909.000000       909.000000  909.000000  \n",
       "mean     0.710671        0.510451     99180.389373    0.201320  \n",
       "std      0.453701        0.500166     56378.063765    0.401207  \n",
       "min      0.000000        0.000000       106.670000    0.000000  \n",
       "25%      0.000000        0.000000     49872.330000    0.000000  \n",
       "50%      1.000000        1.000000     99444.020000    0.000000  \n",
       "75%      1.000000        1.000000    145759.700000    0.000000  \n",
       "max      1.000000        1.000000    199390.450000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        creditscore           age       tenure        balance  numofproducts  \\\n",
       "count  10000.000000  10000.000000  9091.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800     4.997690   76485.889288       1.530200   \n",
       "std       96.653299     10.487806     2.894723   62397.405202       0.581654   \n",
       "min      350.000000     18.000000     0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000     2.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000     5.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000     7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000    10.000000  250898.090000       4.000000   \n",
       "\n",
       "         hascrcard  isactivemember  estimatedsalary        exited  \n",
       "count  10000.00000    10000.000000     10000.000000  10000.000000  \n",
       "mean       0.70550        0.515100    100090.239881      0.203700  \n",
       "std        0.45584        0.499797     57510.492818      0.402769  \n",
       "min        0.00000        0.000000        11.580000      0.000000  \n",
       "25%        0.00000        0.000000     51002.110000      0.000000  \n",
       "50%        1.00000        1.000000    100193.915000      0.000000  \n",
       "75%        1.00000        1.000000    149388.247500      0.000000  \n",
       "max        1.00000        1.000000    199992.480000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные с NaN в колонке `tenure` выглядят вполне нормально, поэтому было решено заменить их на рандомные значения чтобы не изменить распреление самих данных, и не потерять лишние данные. Посмотрим на распределение величин до и после"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['tenure'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nan = df[df['tenure'].isna()]['tenure'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list = []\n",
    "for i in range(len(index_nan)):\n",
    "    rand_list.append(random.randint(df['tenure'].min(), df['tenure'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_series = pd.Series(rand_list, index=index_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[index_nan,'tenure'] = rand_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['tenure'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение на глаз почти не изменилось!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   creditscore      10000 non-null  int64  \n",
      " 1   geography        10000 non-null  object \n",
      " 2   gender           10000 non-null  object \n",
      " 3   age              10000 non-null  int64  \n",
      " 4   tenure           10000 non-null  float64\n",
      " 5   balance          10000 non-null  float64\n",
      " 6   numofproducts    10000 non-null  int64  \n",
      " 7   hascrcard        10000 non-null  int64  \n",
      " 8   isactivemember   10000 non-null  int64  \n",
      " 9   estimatedsalary  10000 non-null  float64\n",
      " 10  exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавил сверху код с заменой NaN на рандомные значения, само распределение не сильно(либо вовсе не) изменилось!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим тип данных в колонке `tenure` с 'object' на 'int64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tenure'] = df['tenure'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   creditscore      10000 non-null  int64  \n",
      " 1   geography        10000 non-null  object \n",
      " 2   gender           10000 non-null  object \n",
      " 3   age              10000 non-null  int64  \n",
      " 4   tenure           10000 non-null  int64  \n",
      " 5   balance          10000 non-null  float64\n",
      " 6   numofproducts    10000 non-null  int64  \n",
      " 7   hascrcard        10000 non-null  int64  \n",
      " 8   isactivemember   10000 non-null  int64  \n",
      " 9   estimatedsalary  10000 non-null  float64\n",
      " 10  exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применили технику OHE для прямого декодирования данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore  age  tenure    balance  numofproducts  hascrcard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   isactivemember  estimatedsalary  exited  geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   creditscore        10000 non-null  int64  \n",
      " 1   age                10000 non-null  int64  \n",
      " 2   tenure             10000 non-null  int64  \n",
      " 3   balance            10000 non-null  float64\n",
      " 4   numofproducts      10000 non-null  int64  \n",
      " 5   hascrcard          10000 non-null  int64  \n",
      " 6   isactivemember     10000 non-null  int64  \n",
      " 7   estimatedsalary    10000 non-null  float64\n",
      " 8   exited             10000 non-null  int64  \n",
      " 9   geography_Germany  10000 non-null  uint8  \n",
      " 10  geography_Spain    10000 non-null  uint8  \n",
      " 11  gender_Male        10000 non-null  uint8  \n",
      "dtypes: float64(2), int64(7), uint8(3)\n",
      "memory usage: 732.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь маштабируем данные для количественных признаков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['creditscore','age','tenure', 'balance', 'numofproducts', 'estimatedsalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric] = scaler.transform(df[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Вывод** \n",
    "\n",
    "Теперь после обработки данных можно их использовать для дальнейшего построения модели. Можно заметить что в данных присутствуют как категориальные признаки так и численные, поэтому применили технику OHE для прямого декодирования категориальных данных. Приступим к построению моделей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследуем `1-ю модель (Логистическая регрессия)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем joblib для сохранения моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "import joblib\n",
    "save_dir = mkdtemp()\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['exited'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid_n_test = train_test_split(df, test_size=0.4, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid, df_test = train_test_split(df_valid_n_test, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['exited'], axis=1)\n",
    "target_train = df_train['exited']\n",
    "features_valid = df_valid.drop(['exited'], axis=1)\n",
    "target_valid = df_valid['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4804\n",
      "1    1196\n",
      "Name: exited, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1582\n",
       "1     418\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train['exited'].value_counts())\n",
    "print()\n",
    "df_valid['exited'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить сразу **несбалансированность данных**, с которой мы будем бороться в след. пункте!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33389544688026984\n",
      "roc_auc_score = 0.7581872017130519\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train,target_train) \n",
    "predict_valid = model.predict(features_valid)\n",
    "probabilities_one_valid = model.predict_proba(features_valid)[:,1]\n",
    "\n",
    "print(f1_score(target_valid, predict_valid))\n",
    "print('roc_auc_score =',roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmp4yask5cm/model.joblib.log.reg']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_logistic_reg = os.path.join(save_dir, 'model.joblib.log.reg')\n",
    "joblib.dump(model, filename_logistic_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак модель создали, поиграем теперь со значением threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | f1 = 0.346\n",
      "Порог = 0.01 | f1 = 0.346\n",
      "Порог = 0.01 | f1 = 0.346\n",
      "Порог = 0.01 | f1 = 0.347\n",
      "Порог = 0.02 | f1 = 0.348\n",
      "Порог = 0.03 | f1 = 0.352\n",
      "Порог = 0.03 | f1 = 0.358\n",
      "Порог = 0.04 | f1 = 0.363\n",
      "Порог = 0.04 | f1 = 0.369\n",
      "Порог = 0.04 | f1 = 0.375\n",
      "Порог = 0.05 | f1 = 0.380\n",
      "Порог = 0.06 | f1 = 0.382\n",
      "Порог = 0.06 | f1 = 0.391\n",
      "Порог = 0.07 | f1 = 0.394\n",
      "Порог = 0.07 | f1 = 0.398\n",
      "Порог = 0.07 | f1 = 0.403\n",
      "Порог = 0.08 | f1 = 0.406\n",
      "Порог = 0.09 | f1 = 0.407\n",
      "Порог = 0.09 | f1 = 0.413\n",
      "Порог = 0.10 | f1 = 0.416\n",
      "Порог = 0.10 | f1 = 0.423\n",
      "Порог = 0.10 | f1 = 0.423\n",
      "Порог = 0.11 | f1 = 0.428\n",
      "Порог = 0.12 | f1 = 0.437\n",
      "Порог = 0.12 | f1 = 0.444\n",
      "Порог = 0.12 | f1 = 0.448\n",
      "Порог = 0.13 | f1 = 0.456\n",
      "Порог = 0.14 | f1 = 0.462\n",
      "Порог = 0.14 | f1 = 0.462\n",
      "Порог = 0.14 | f1 = 0.464\n",
      "Порог = 0.15 | f1 = 0.461\n",
      "Порог = 0.15 | f1 = 0.465\n",
      "Порог = 0.16 | f1 = 0.466\n",
      "Порог = 0.17 | f1 = 0.469\n",
      "Порог = 0.17 | f1 = 0.474\n",
      "Порог = 0.18 | f1 = 0.480\n",
      "Порог = 0.18 | f1 = 0.480\n",
      "Порог = 0.18 | f1 = 0.480\n",
      "Порог = 0.19 | f1 = 0.479\n",
      "Порог = 0.20 | f1 = 0.478\n",
      "Порог = 0.20 | f1 = 0.480\n",
      "Порог = 0.21 | f1 = 0.479\n",
      "Порог = 0.21 | f1 = 0.481\n",
      "Порог = 0.21 | f1 = 0.480\n",
      "Порог = 0.22 | f1 = 0.482\n",
      "Порог = 0.23 | f1 = 0.489\n",
      "Порог = 0.23 | f1 = 0.491\n",
      "Порог = 0.24 | f1 = 0.496\n",
      "Порог = 0.24 | f1 = 0.498\n",
      "Порог = 0.24 | f1 = 0.495\n",
      "Порог = 0.25 | f1 = 0.493\n",
      "Порог = 0.26 | f1 = 0.497\n",
      "Порог = 0.26 | f1 = 0.495\n",
      "Порог = 0.27 | f1 = 0.496\n",
      "Порог = 0.27 | f1 = 0.496\n",
      "Порог = 0.28 | f1 = 0.487\n",
      "Порог = 0.28 | f1 = 0.489\n",
      "Порог = 0.29 | f1 = 0.487\n",
      "Порог = 0.29 | f1 = 0.487\n",
      "Порог = 0.29 | f1 = 0.486\n",
      "Порог = 0.30 | f1 = 0.483\n",
      "Порог = 0.30 | f1 = 0.480\n",
      "Порог = 0.31 | f1 = 0.479\n",
      "Порог = 0.32 | f1 = 0.478\n",
      "Порог = 0.32 | f1 = 0.470\n",
      "Порог = 0.33 | f1 = 0.465\n",
      "Порог = 0.33 | f1 = 0.465\n",
      "Порог = 0.34 | f1 = 0.464\n",
      "Порог = 0.34 | f1 = 0.460\n",
      "Порог = 0.35 | f1 = 0.455\n",
      "Порог = 0.35 | f1 = 0.455\n",
      "Порог = 0.35 | f1 = 0.448\n",
      "Порог = 0.36 | f1 = 0.445\n",
      "Порог = 0.36 | f1 = 0.438\n",
      "Порог = 0.37 | f1 = 0.435\n",
      "Порог = 0.38 | f1 = 0.422\n",
      "Порог = 0.38 | f1 = 0.419\n",
      "Порог = 0.39 | f1 = 0.409\n",
      "Порог = 0.39 | f1 = 0.406\n",
      "Порог = 0.40 | f1 = 0.398\n",
      "Порог = 0.40 | f1 = 0.399\n",
      "Порог = 0.41 | f1 = 0.397\n",
      "Порог = 0.41 | f1 = 0.394\n",
      "Порог = 0.42 | f1 = 0.391\n",
      "Порог = 0.42 | f1 = 0.390\n",
      "Порог = 0.42 | f1 = 0.387\n",
      "Порог = 0.43 | f1 = 0.375\n",
      "Порог = 0.43 | f1 = 0.376\n",
      "Порог = 0.44 | f1 = 0.368\n",
      "Порог = 0.45 | f1 = 0.367\n",
      "Порог = 0.45 | f1 = 0.366\n",
      "Порог = 0.46 | f1 = 0.365\n",
      "Порог = 0.46 | f1 = 0.367\n",
      "Порог = 0.47 | f1 = 0.367\n",
      "Порог = 0.47 | f1 = 0.369\n",
      "Порог = 0.48 | f1 = 0.366\n",
      "Порог = 0.48 | f1 = 0.356\n",
      "Порог = 0.48 | f1 = 0.352\n",
      "Порог = 0.49 | f1 = 0.347\n",
      "Порог = 0.49 | f1 = 0.344\n",
      "Порог = 0.50 | f1 = 0.334\n",
      "Порог = 0.51 | f1 = 0.325\n",
      "Порог = 0.51 | f1 = 0.315\n",
      "Порог = 0.52 | f1 = 0.309\n",
      "Порог = 0.52 | f1 = 0.312\n",
      "Порог = 0.53 | f1 = 0.309\n",
      "Порог = 0.53 | f1 = 0.301\n",
      "Порог = 0.54 | f1 = 0.299\n",
      "Порог = 0.54 | f1 = 0.283\n",
      "Порог = 0.55 | f1 = 0.275\n",
      "Порог = 0.55 | f1 = 0.273\n",
      "Порог = 0.56 | f1 = 0.264\n",
      "Порог = 0.56 | f1 = 0.259\n",
      "Порог = 0.57 | f1 = 0.259\n",
      "Порог = 0.57 | f1 = 0.257\n",
      "Порог = 0.58 | f1 = 0.258\n",
      "Порог = 0.58 | f1 = 0.246\n",
      "Порог = 0.58 | f1 = 0.244\n",
      "Порог = 0.59 | f1 = 0.230\n",
      "Порог = 0.59 | f1 = 0.223\n",
      "Порог = 0.60 | f1 = 0.209\n",
      "Порог = 0.60 | f1 = 0.204\n",
      "Порог = 0.61 | f1 = 0.200\n",
      "Порог = 0.61 | f1 = 0.196\n",
      "Порог = 0.62 | f1 = 0.186\n",
      "Порог = 0.62 | f1 = 0.175\n",
      "Порог = 0.63 | f1 = 0.163\n",
      "Порог = 0.64 | f1 = 0.155\n",
      "Порог = 0.64 | f1 = 0.148\n",
      "Порог = 0.65 | f1 = 0.144\n",
      "Порог = 0.65 | f1 = 0.141\n",
      "Порог = 0.66 | f1 = 0.141\n",
      "Порог = 0.66 | f1 = 0.134\n",
      "Порог = 0.67 | f1 = 0.126\n",
      "Порог = 0.67 | f1 = 0.126\n",
      "Порог = 0.68 | f1 = 0.114\n",
      "Порог = 0.68 | f1 = 0.114\n",
      "Порог = 0.69 | f1 = 0.102\n",
      "Порог = 0.69 | f1 = 0.102\n",
      "Порог = 0.70 | f1 = 0.089\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = joblib.load(filename_logistic_reg).predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.005):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_val = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Порог = {:.2f} | f1 = {:.3f}\".format(\n",
    "        threshold, f1_score_val))\n",
    "    if best_f1 < f1_score_val:\n",
    "        best_threshold = threshold\n",
    "        best_f1 = f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score: 0.49758919961427195 ,\n",
      "best threshold : 0.24\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score: {} ,\\nbest threshold : {}'.format(best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно что при изменение порога увеличивается значение f1 метрики!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследуем `2-ю модель (Дерево решений)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбираем оптимальную модель перебирая гиперпараметры, в данном случае max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.0\n",
      "max_depth = 2 : 0.5217391304347825\n",
      "max_depth = 3 : 0.4234875444839857\n",
      "max_depth = 4 : 0.5528700906344411\n",
      "max_depth = 5 : 0.5406249999999999\n",
      "max_depth = 6 : 0.5696969696969697\n",
      "max_depth = 7 : 0.5320813771517998\n",
      "max_depth = 8 : 0.5435114503816794\n",
      "max_depth = 9 : 0.5637393767705382\n",
      "max_depth = 10 : 0.5379310344827586\n",
      "max_depth = 11 : 0.5153538050734313\n",
      "max_depth = 12 : 0.5000000000000001\n",
      "max_depth = 13 : 0.5032092426187419\n",
      "max_depth = 14 : 0.5012468827930175\n",
      "max_depth = 15 : 0.5\n",
      "max_depth = 16 : 0.5012224938875306\n",
      "max_depth = 17 : 0.5024271844660193\n",
      "max_depth = 18 : 0.49818621523579204\n",
      "max_depth = 19 : 0.48984468339307047\n"
     ]
    }
   ],
   "source": [
    "best_res = 0\n",
    "best_model = None\n",
    "for i in range(1,20):\n",
    "    model = DecisionTreeClassifier(random_state = 12345,max_depth=i)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    res = f1_score(target_valid, predictions)\n",
    "    print('max_depth = {} :'.format(i), res)\n",
    "    if res > best_res:\n",
    "        best_res = res\n",
    "        best_model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score for DecisionTree = 0.5696969696969697\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score for DecisionTree =', best_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmp4yask5cm/model.joblib.decision_tree']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_decision_tree = os.path.join(save_dir, 'model.joblib.decision_tree')\n",
    "joblib.dump(best_model, filename_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | f1 = 0.342\n",
      "Порог = 0.01 | f1 = 0.342\n",
      "Порог = 0.01 | f1 = 0.342\n",
      "Порог = 0.01 | f1 = 0.398\n",
      "Порог = 0.02 | f1 = 0.398\n",
      "Порог = 0.03 | f1 = 0.398\n",
      "Порог = 0.03 | f1 = 0.397\n",
      "Порог = 0.04 | f1 = 0.397\n",
      "Порог = 0.04 | f1 = 0.397\n",
      "Порог = 0.04 | f1 = 0.408\n",
      "Порог = 0.05 | f1 = 0.408\n",
      "Порог = 0.06 | f1 = 0.408\n",
      "Порог = 0.06 | f1 = 0.408\n",
      "Порог = 0.07 | f1 = 0.408\n",
      "Порог = 0.07 | f1 = 0.456\n",
      "Порог = 0.07 | f1 = 0.531\n",
      "Порог = 0.08 | f1 = 0.531\n",
      "Порог = 0.09 | f1 = 0.537\n",
      "Порог = 0.09 | f1 = 0.537\n",
      "Порог = 0.10 | f1 = 0.537\n",
      "Порог = 0.10 | f1 = 0.537\n",
      "Порог = 0.10 | f1 = 0.537\n",
      "Порог = 0.11 | f1 = 0.537\n",
      "Порог = 0.12 | f1 = 0.537\n",
      "Порог = 0.12 | f1 = 0.535\n",
      "Порог = 0.12 | f1 = 0.535\n",
      "Порог = 0.13 | f1 = 0.535\n",
      "Порог = 0.14 | f1 = 0.535\n",
      "Порог = 0.14 | f1 = 0.535\n",
      "Порог = 0.14 | f1 = 0.535\n",
      "Порог = 0.15 | f1 = 0.535\n",
      "Порог = 0.15 | f1 = 0.535\n",
      "Порог = 0.16 | f1 = 0.535\n",
      "Порог = 0.17 | f1 = 0.535\n",
      "Порог = 0.17 | f1 = 0.535\n",
      "Порог = 0.18 | f1 = 0.530\n",
      "Порог = 0.18 | f1 = 0.530\n",
      "Порог = 0.18 | f1 = 0.530\n",
      "Порог = 0.19 | f1 = 0.530\n",
      "Порог = 0.20 | f1 = 0.530\n",
      "Порог = 0.20 | f1 = 0.530\n",
      "Порог = 0.21 | f1 = 0.530\n",
      "Порог = 0.21 | f1 = 0.530\n",
      "Порог = 0.21 | f1 = 0.560\n",
      "Порог = 0.22 | f1 = 0.560\n",
      "Порог = 0.23 | f1 = 0.568\n",
      "Порог = 0.23 | f1 = 0.568\n",
      "Порог = 0.24 | f1 = 0.568\n",
      "Порог = 0.24 | f1 = 0.568\n",
      "Порог = 0.24 | f1 = 0.568\n",
      "Порог = 0.25 | f1 = 0.570\n",
      "Порог = 0.26 | f1 = 0.573\n",
      "Порог = 0.26 | f1 = 0.599\n",
      "Порог = 0.27 | f1 = 0.599\n",
      "Порог = 0.27 | f1 = 0.599\n",
      "Порог = 0.28 | f1 = 0.599\n",
      "Порог = 0.28 | f1 = 0.599\n",
      "Порог = 0.29 | f1 = 0.599\n",
      "Порог = 0.29 | f1 = 0.599\n",
      "Порог = 0.29 | f1 = 0.599\n",
      "Порог = 0.30 | f1 = 0.599\n",
      "Порог = 0.30 | f1 = 0.599\n",
      "Порог = 0.31 | f1 = 0.599\n",
      "Порог = 0.32 | f1 = 0.594\n",
      "Порог = 0.32 | f1 = 0.594\n",
      "Порог = 0.33 | f1 = 0.594\n",
      "Порог = 0.33 | f1 = 0.594\n",
      "Порог = 0.34 | f1 = 0.594\n",
      "Порог = 0.34 | f1 = 0.594\n",
      "Порог = 0.35 | f1 = 0.594\n",
      "Порог = 0.35 | f1 = 0.594\n",
      "Порог = 0.35 | f1 = 0.594\n",
      "Порог = 0.36 | f1 = 0.594\n",
      "Порог = 0.36 | f1 = 0.594\n",
      "Порог = 0.37 | f1 = 0.594\n",
      "Порог = 0.38 | f1 = 0.594\n",
      "Порог = 0.38 | f1 = 0.594\n",
      "Порог = 0.39 | f1 = 0.584\n",
      "Порог = 0.39 | f1 = 0.584\n",
      "Порог = 0.40 | f1 = 0.584\n",
      "Порог = 0.40 | f1 = 0.584\n",
      "Порог = 0.41 | f1 = 0.573\n",
      "Порог = 0.41 | f1 = 0.573\n",
      "Порог = 0.42 | f1 = 0.573\n",
      "Порог = 0.42 | f1 = 0.573\n",
      "Порог = 0.42 | f1 = 0.573\n",
      "Порог = 0.43 | f1 = 0.573\n",
      "Порог = 0.43 | f1 = 0.573\n",
      "Порог = 0.44 | f1 = 0.573\n",
      "Порог = 0.45 | f1 = 0.573\n",
      "Порог = 0.45 | f1 = 0.573\n",
      "Порог = 0.46 | f1 = 0.573\n",
      "Порог = 0.46 | f1 = 0.573\n",
      "Порог = 0.47 | f1 = 0.573\n",
      "Порог = 0.47 | f1 = 0.573\n",
      "Порог = 0.48 | f1 = 0.573\n",
      "Порог = 0.48 | f1 = 0.573\n",
      "Порог = 0.48 | f1 = 0.573\n",
      "Порог = 0.49 | f1 = 0.573\n",
      "Порог = 0.49 | f1 = 0.573\n",
      "Порог = 0.50 | f1 = 0.570\n",
      "Порог = 0.51 | f1 = 0.570\n",
      "Порог = 0.51 | f1 = 0.570\n",
      "Порог = 0.52 | f1 = 0.570\n",
      "Порог = 0.52 | f1 = 0.570\n",
      "Порог = 0.53 | f1 = 0.570\n",
      "Порог = 0.53 | f1 = 0.570\n",
      "Порог = 0.54 | f1 = 0.570\n",
      "Порог = 0.54 | f1 = 0.570\n",
      "Порог = 0.55 | f1 = 0.570\n",
      "Порог = 0.55 | f1 = 0.536\n",
      "Порог = 0.56 | f1 = 0.536\n",
      "Порог = 0.56 | f1 = 0.536\n",
      "Порог = 0.57 | f1 = 0.536\n",
      "Порог = 0.57 | f1 = 0.536\n",
      "Порог = 0.58 | f1 = 0.536\n",
      "Порог = 0.58 | f1 = 0.536\n",
      "Порог = 0.58 | f1 = 0.536\n",
      "Порог = 0.59 | f1 = 0.536\n",
      "Порог = 0.59 | f1 = 0.536\n",
      "Порог = 0.60 | f1 = 0.536\n",
      "Порог = 0.60 | f1 = 0.536\n",
      "Порог = 0.61 | f1 = 0.536\n",
      "Порог = 0.61 | f1 = 0.536\n",
      "Порог = 0.62 | f1 = 0.536\n",
      "Порог = 0.62 | f1 = 0.536\n",
      "Порог = 0.63 | f1 = 0.536\n",
      "Порог = 0.64 | f1 = 0.536\n",
      "Порог = 0.64 | f1 = 0.536\n",
      "Порог = 0.65 | f1 = 0.536\n",
      "Порог = 0.65 | f1 = 0.536\n",
      "Порог = 0.66 | f1 = 0.536\n",
      "Порог = 0.66 | f1 = 0.536\n",
      "Порог = 0.67 | f1 = 0.536\n",
      "Порог = 0.67 | f1 = 0.536\n",
      "Порог = 0.68 | f1 = 0.536\n",
      "Порог = 0.68 | f1 = 0.536\n",
      "Порог = 0.69 | f1 = 0.507\n",
      "Порог = 0.69 | f1 = 0.507\n",
      "Порог = 0.70 | f1 = 0.507\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = joblib.load(filename_decision_tree).predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.005):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_val = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Порог = {:.2f} | f1 = {:.3f}\".format(\n",
    "        threshold, f1_score_val))\n",
    "    if best_f1 < f1_score_val:\n",
    "        best_threshold = threshold\n",
    "        best_f1 = f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score: 0.5987577639751551 ,\n",
      "best threshold : 0.26\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score: {} ,\\nbest threshold : {}'.format(best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять как и в предыдущем случае значение f1_score увеличивается при снижение порога!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследуем `3-ю модель (Случайный лес)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбираем оптимальную модель перебирая гиперпараметры, в данном случае n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_estimator = 1 : 0.5105882352941177\n",
      "number_estimator = 2 : 0.428341384863124\n",
      "number_estimator = 3 : 0.5384615384615384\n",
      "number_estimator = 4 : 0.49149922720247297\n",
      "number_estimator = 5 : 0.545201668984701\n",
      "number_estimator = 6 : 0.5161290322580645\n",
      "number_estimator = 7 : 0.5673758865248227\n",
      "number_estimator = 8 : 0.5424242424242425\n",
      "number_estimator = 9 : 0.5857142857142856\n",
      "number_estimator = 10 : 0.5688622754491017\n",
      "number_estimator = 11 : 0.584045584045584\n",
      "number_estimator = 12 : 0.5610859728506787\n",
      "number_estimator = 13 : 0.5730659025787965\n",
      "number_estimator = 14 : 0.5671191553544495\n",
      "number_estimator = 15 : 0.5805515239477503\n",
      "number_estimator = 16 : 0.5761194029850746\n",
      "number_estimator = 17 : 0.5747800586510264\n",
      "number_estimator = 18 : 0.572289156626506\n",
      "number_estimator = 19 : 0.581021897810219\n",
      "number_estimator = 20 : 0.5735735735735735\n",
      "number_estimator = 21 : 0.5781021897810219\n",
      "number_estimator = 22 : 0.5688350983358548\n",
      "number_estimator = 23 : 0.5873715124816447\n",
      "number_estimator = 24 : 0.5662650602409639\n",
      "number_estimator = 25 : 0.5726872246696035\n",
      "number_estimator = 26 : 0.5667166416791604\n",
      "number_estimator = 27 : 0.5847953216374269\n",
      "number_estimator = 28 : 0.5701492537313433\n",
      "number_estimator = 29 : 0.5830903790087464\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "for est in range(1, 30):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est) \n",
    "    model.fit(features_train, target_train) \n",
    "    predictions = model.predict(features_valid)\n",
    "    res = f1_score(target_valid, predictions) \n",
    "    print('number_estimator = {} :'.format(est), res)\n",
    "    if res > best_result:\n",
    "        best_model = model \n",
    "        best_result = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score for Random Forest =  0.5873715124816447\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score for Random Forest = ', best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmp4yask5cm/model.joblib.random_forest']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_random_forest = os.path.join(save_dir, 'model.joblib.random_forest')\n",
    "joblib.dump(best_model, filename_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=23, random_state=12345)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load(filename_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | f1 = 0.395\n",
      "Порог = 0.01 | f1 = 0.395\n",
      "Порог = 0.01 | f1 = 0.395\n",
      "Порог = 0.01 | f1 = 0.395\n",
      "Порог = 0.02 | f1 = 0.395\n",
      "Порог = 0.03 | f1 = 0.395\n",
      "Порог = 0.03 | f1 = 0.395\n",
      "Порог = 0.04 | f1 = 0.395\n",
      "Порог = 0.04 | f1 = 0.395\n",
      "Порог = 0.04 | f1 = 0.441\n",
      "Порог = 0.05 | f1 = 0.441\n",
      "Порог = 0.06 | f1 = 0.441\n",
      "Порог = 0.06 | f1 = 0.441\n",
      "Порог = 0.07 | f1 = 0.441\n",
      "Порог = 0.07 | f1 = 0.441\n",
      "Порог = 0.07 | f1 = 0.441\n",
      "Порог = 0.08 | f1 = 0.441\n",
      "Порог = 0.09 | f1 = 0.441\n",
      "Порог = 0.09 | f1 = 0.483\n",
      "Порог = 0.10 | f1 = 0.483\n",
      "Порог = 0.10 | f1 = 0.483\n",
      "Порог = 0.10 | f1 = 0.483\n",
      "Порог = 0.11 | f1 = 0.483\n",
      "Порог = 0.12 | f1 = 0.483\n",
      "Порог = 0.12 | f1 = 0.483\n",
      "Порог = 0.12 | f1 = 0.483\n",
      "Порог = 0.13 | f1 = 0.483\n",
      "Порог = 0.14 | f1 = 0.513\n",
      "Порог = 0.14 | f1 = 0.513\n",
      "Порог = 0.14 | f1 = 0.513\n",
      "Порог = 0.15 | f1 = 0.513\n",
      "Порог = 0.15 | f1 = 0.513\n",
      "Порог = 0.16 | f1 = 0.513\n",
      "Порог = 0.17 | f1 = 0.513\n",
      "Порог = 0.17 | f1 = 0.513\n",
      "Порог = 0.18 | f1 = 0.560\n",
      "Порог = 0.18 | f1 = 0.560\n",
      "Порог = 0.18 | f1 = 0.560\n",
      "Порог = 0.19 | f1 = 0.560\n",
      "Порог = 0.20 | f1 = 0.560\n",
      "Порог = 0.20 | f1 = 0.560\n",
      "Порог = 0.21 | f1 = 0.560\n",
      "Порог = 0.21 | f1 = 0.560\n",
      "Порог = 0.21 | f1 = 0.560\n",
      "Порог = 0.22 | f1 = 0.588\n",
      "Порог = 0.23 | f1 = 0.588\n",
      "Порог = 0.23 | f1 = 0.588\n",
      "Порог = 0.24 | f1 = 0.588\n",
      "Порог = 0.24 | f1 = 0.588\n",
      "Порог = 0.24 | f1 = 0.588\n",
      "Порог = 0.25 | f1 = 0.588\n",
      "Порог = 0.26 | f1 = 0.588\n",
      "Порог = 0.26 | f1 = 0.588\n",
      "Порог = 0.27 | f1 = 0.597\n",
      "Порог = 0.27 | f1 = 0.597\n",
      "Порог = 0.28 | f1 = 0.597\n",
      "Порог = 0.28 | f1 = 0.597\n",
      "Порог = 0.29 | f1 = 0.597\n",
      "Порог = 0.29 | f1 = 0.597\n",
      "Порог = 0.29 | f1 = 0.597\n",
      "Порог = 0.30 | f1 = 0.597\n",
      "Порог = 0.30 | f1 = 0.606\n",
      "Порог = 0.31 | f1 = 0.606\n",
      "Порог = 0.32 | f1 = 0.606\n",
      "Порог = 0.32 | f1 = 0.606\n",
      "Порог = 0.33 | f1 = 0.606\n",
      "Порог = 0.33 | f1 = 0.606\n",
      "Порог = 0.34 | f1 = 0.606\n",
      "Порог = 0.34 | f1 = 0.606\n",
      "Порог = 0.35 | f1 = 0.606\n",
      "Порог = 0.35 | f1 = 0.599\n",
      "Порог = 0.35 | f1 = 0.599\n",
      "Порог = 0.36 | f1 = 0.599\n",
      "Порог = 0.36 | f1 = 0.599\n",
      "Порог = 0.37 | f1 = 0.599\n",
      "Порог = 0.38 | f1 = 0.599\n",
      "Порог = 0.38 | f1 = 0.599\n",
      "Порог = 0.39 | f1 = 0.599\n",
      "Порог = 0.39 | f1 = 0.599\n",
      "Порог = 0.40 | f1 = 0.603\n",
      "Порог = 0.40 | f1 = 0.603\n",
      "Порог = 0.41 | f1 = 0.603\n",
      "Порог = 0.41 | f1 = 0.603\n",
      "Порог = 0.42 | f1 = 0.603\n",
      "Порог = 0.42 | f1 = 0.603\n",
      "Порог = 0.42 | f1 = 0.603\n",
      "Порог = 0.43 | f1 = 0.603\n",
      "Порог = 0.43 | f1 = 0.590\n",
      "Порог = 0.44 | f1 = 0.590\n",
      "Порог = 0.45 | f1 = 0.590\n",
      "Порог = 0.45 | f1 = 0.590\n",
      "Порог = 0.46 | f1 = 0.590\n",
      "Порог = 0.46 | f1 = 0.590\n",
      "Порог = 0.47 | f1 = 0.590\n",
      "Порог = 0.47 | f1 = 0.590\n",
      "Порог = 0.48 | f1 = 0.590\n",
      "Порог = 0.48 | f1 = 0.587\n",
      "Порог = 0.48 | f1 = 0.587\n",
      "Порог = 0.49 | f1 = 0.587\n",
      "Порог = 0.49 | f1 = 0.587\n",
      "Порог = 0.50 | f1 = 0.587\n",
      "Порог = 0.51 | f1 = 0.587\n",
      "Порог = 0.51 | f1 = 0.587\n",
      "Порог = 0.52 | f1 = 0.587\n",
      "Порог = 0.52 | f1 = 0.587\n",
      "Порог = 0.53 | f1 = 0.556\n",
      "Порог = 0.53 | f1 = 0.556\n",
      "Порог = 0.54 | f1 = 0.556\n",
      "Порог = 0.54 | f1 = 0.556\n",
      "Порог = 0.55 | f1 = 0.556\n",
      "Порог = 0.55 | f1 = 0.556\n",
      "Порог = 0.56 | f1 = 0.556\n",
      "Порог = 0.56 | f1 = 0.556\n",
      "Порог = 0.57 | f1 = 0.556\n",
      "Порог = 0.57 | f1 = 0.524\n",
      "Порог = 0.58 | f1 = 0.524\n",
      "Порог = 0.58 | f1 = 0.524\n",
      "Порог = 0.58 | f1 = 0.524\n",
      "Порог = 0.59 | f1 = 0.524\n",
      "Порог = 0.59 | f1 = 0.524\n",
      "Порог = 0.60 | f1 = 0.524\n",
      "Порог = 0.60 | f1 = 0.524\n",
      "Порог = 0.61 | f1 = 0.500\n",
      "Порог = 0.61 | f1 = 0.500\n",
      "Порог = 0.62 | f1 = 0.500\n",
      "Порог = 0.62 | f1 = 0.500\n",
      "Порог = 0.63 | f1 = 0.500\n",
      "Порог = 0.64 | f1 = 0.500\n",
      "Порог = 0.64 | f1 = 0.500\n",
      "Порог = 0.65 | f1 = 0.500\n",
      "Порог = 0.65 | f1 = 0.500\n",
      "Порог = 0.66 | f1 = 0.479\n",
      "Порог = 0.66 | f1 = 0.479\n",
      "Порог = 0.67 | f1 = 0.479\n",
      "Порог = 0.67 | f1 = 0.479\n",
      "Порог = 0.68 | f1 = 0.479\n",
      "Порог = 0.68 | f1 = 0.479\n",
      "Порог = 0.69 | f1 = 0.479\n",
      "Порог = 0.69 | f1 = 0.479\n",
      "Порог = 0.70 | f1 = 0.479\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = joblib.load(filename_random_forest).predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.005):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_val = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Порог = {:.2f} | f1 = {:.3f}\".format(\n",
    "        threshold, f1_score_val))\n",
    "    if best_f1 < f1_score_val:\n",
    "        best_threshold = threshold\n",
    "        best_f1 = f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score: 0.6057142857142858 ,\n",
      "best threshold : 0.305\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score: {} ,\\nbest threshold : {}'.format(best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первый метод борьбы с дисбалансом мы выбрали применение параметра `class_weight='balanced'`.\n",
    "\n",
    "#### Сначала применяем к `1-ой модели (логистическая регрессия)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = 0.4888507718696398\n",
      "roc_auc_score = 0.7631442846859707\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "model.fit(features_train,target_train) \n",
    "predict_valid = model.predict(features_valid)\n",
    "probabilities_one_valid = model.predict_proba(features_valid)[:,1]\n",
    "\n",
    "print('f1_score =',f1_score(target_valid, predict_valid))\n",
    "print('roc_auc_score =',roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика достаточно сильно изменилась в сравенение с метрикой (без изменения threshold) у модели без данного параметра, но такого значения всё равно не достаточно в условиях данной задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmp4yask5cm/model.joblib.log.reg.weight']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_logistic_reg_weighted = os.path.join(save_dir, 'model.joblib.log.reg.weight')\n",
    "joblib.dump(model, filename_logistic_reg_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебираем значения threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | f1 = 0.346\n",
      "Порог = 0.01 | f1 = 0.346\n",
      "Порог = 0.01 | f1 = 0.346\n",
      "Порог = 0.01 | f1 = 0.346\n",
      "Порог = 0.02 | f1 = 0.346\n",
      "Порог = 0.03 | f1 = 0.346\n",
      "Порог = 0.03 | f1 = 0.346\n",
      "Порог = 0.04 | f1 = 0.346\n",
      "Порог = 0.04 | f1 = 0.346\n",
      "Порог = 0.04 | f1 = 0.346\n",
      "Порог = 0.05 | f1 = 0.346\n",
      "Порог = 0.06 | f1 = 0.347\n",
      "Порог = 0.06 | f1 = 0.347\n",
      "Порог = 0.07 | f1 = 0.347\n",
      "Порог = 0.07 | f1 = 0.348\n",
      "Порог = 0.07 | f1 = 0.349\n",
      "Порог = 0.08 | f1 = 0.349\n",
      "Порог = 0.09 | f1 = 0.351\n",
      "Порог = 0.09 | f1 = 0.352\n",
      "Порог = 0.10 | f1 = 0.353\n",
      "Порог = 0.10 | f1 = 0.354\n",
      "Порог = 0.10 | f1 = 0.356\n",
      "Порог = 0.11 | f1 = 0.357\n",
      "Порог = 0.12 | f1 = 0.358\n",
      "Порог = 0.12 | f1 = 0.359\n",
      "Порог = 0.12 | f1 = 0.361\n",
      "Порог = 0.13 | f1 = 0.364\n",
      "Порог = 0.14 | f1 = 0.366\n",
      "Порог = 0.14 | f1 = 0.368\n",
      "Порог = 0.14 | f1 = 0.369\n",
      "Порог = 0.15 | f1 = 0.371\n",
      "Порог = 0.15 | f1 = 0.374\n",
      "Порог = 0.16 | f1 = 0.375\n",
      "Порог = 0.17 | f1 = 0.376\n",
      "Порог = 0.17 | f1 = 0.376\n",
      "Порог = 0.18 | f1 = 0.378\n",
      "Порог = 0.18 | f1 = 0.380\n",
      "Порог = 0.18 | f1 = 0.381\n",
      "Порог = 0.19 | f1 = 0.381\n",
      "Порог = 0.20 | f1 = 0.383\n",
      "Порог = 0.20 | f1 = 0.387\n",
      "Порог = 0.21 | f1 = 0.391\n",
      "Порог = 0.21 | f1 = 0.393\n",
      "Порог = 0.21 | f1 = 0.394\n",
      "Порог = 0.22 | f1 = 0.396\n",
      "Порог = 0.23 | f1 = 0.397\n",
      "Порог = 0.23 | f1 = 0.398\n",
      "Порог = 0.24 | f1 = 0.399\n",
      "Порог = 0.24 | f1 = 0.402\n",
      "Порог = 0.24 | f1 = 0.402\n",
      "Порог = 0.25 | f1 = 0.404\n",
      "Порог = 0.26 | f1 = 0.406\n",
      "Порог = 0.26 | f1 = 0.407\n",
      "Порог = 0.27 | f1 = 0.411\n",
      "Порог = 0.27 | f1 = 0.413\n",
      "Порог = 0.28 | f1 = 0.414\n",
      "Порог = 0.28 | f1 = 0.416\n",
      "Порог = 0.29 | f1 = 0.416\n",
      "Порог = 0.29 | f1 = 0.417\n",
      "Порог = 0.29 | f1 = 0.419\n",
      "Порог = 0.30 | f1 = 0.422\n",
      "Порог = 0.30 | f1 = 0.425\n",
      "Порог = 0.31 | f1 = 0.429\n",
      "Порог = 0.32 | f1 = 0.432\n",
      "Порог = 0.32 | f1 = 0.432\n",
      "Порог = 0.33 | f1 = 0.435\n",
      "Порог = 0.33 | f1 = 0.436\n",
      "Порог = 0.34 | f1 = 0.439\n",
      "Порог = 0.34 | f1 = 0.441\n",
      "Порог = 0.35 | f1 = 0.441\n",
      "Порог = 0.35 | f1 = 0.446\n",
      "Порог = 0.35 | f1 = 0.447\n",
      "Порог = 0.36 | f1 = 0.451\n",
      "Порог = 0.36 | f1 = 0.454\n",
      "Порог = 0.37 | f1 = 0.456\n",
      "Порог = 0.38 | f1 = 0.461\n",
      "Порог = 0.38 | f1 = 0.463\n",
      "Порог = 0.39 | f1 = 0.466\n",
      "Порог = 0.39 | f1 = 0.468\n",
      "Порог = 0.40 | f1 = 0.472\n",
      "Порог = 0.40 | f1 = 0.472\n",
      "Порог = 0.41 | f1 = 0.475\n",
      "Порог = 0.41 | f1 = 0.476\n",
      "Порог = 0.42 | f1 = 0.474\n",
      "Порог = 0.42 | f1 = 0.475\n",
      "Порог = 0.42 | f1 = 0.476\n",
      "Порог = 0.43 | f1 = 0.479\n",
      "Порог = 0.43 | f1 = 0.480\n",
      "Порог = 0.44 | f1 = 0.484\n",
      "Порог = 0.45 | f1 = 0.486\n",
      "Порог = 0.45 | f1 = 0.483\n",
      "Порог = 0.46 | f1 = 0.487\n",
      "Порог = 0.46 | f1 = 0.484\n",
      "Порог = 0.47 | f1 = 0.483\n",
      "Порог = 0.47 | f1 = 0.483\n",
      "Порог = 0.48 | f1 = 0.483\n",
      "Порог = 0.48 | f1 = 0.485\n",
      "Порог = 0.48 | f1 = 0.485\n",
      "Порог = 0.49 | f1 = 0.487\n",
      "Порог = 0.49 | f1 = 0.488\n",
      "Порог = 0.50 | f1 = 0.489\n",
      "Порог = 0.51 | f1 = 0.489\n",
      "Порог = 0.51 | f1 = 0.490\n",
      "Порог = 0.52 | f1 = 0.493\n",
      "Порог = 0.52 | f1 = 0.494\n",
      "Порог = 0.53 | f1 = 0.495\n",
      "Порог = 0.53 | f1 = 0.496\n",
      "Порог = 0.54 | f1 = 0.499\n",
      "Порог = 0.54 | f1 = 0.497\n",
      "Порог = 0.55 | f1 = 0.499\n",
      "Порог = 0.55 | f1 = 0.499\n",
      "Порог = 0.56 | f1 = 0.498\n",
      "Порог = 0.56 | f1 = 0.494\n",
      "Порог = 0.57 | f1 = 0.490\n",
      "Порог = 0.57 | f1 = 0.495\n",
      "Порог = 0.58 | f1 = 0.495\n",
      "Порог = 0.58 | f1 = 0.492\n",
      "Порог = 0.58 | f1 = 0.495\n",
      "Порог = 0.59 | f1 = 0.491\n",
      "Порог = 0.59 | f1 = 0.488\n",
      "Порог = 0.60 | f1 = 0.489\n",
      "Порог = 0.60 | f1 = 0.489\n",
      "Порог = 0.61 | f1 = 0.495\n",
      "Порог = 0.61 | f1 = 0.501\n",
      "Порог = 0.62 | f1 = 0.499\n",
      "Порог = 0.62 | f1 = 0.497\n",
      "Порог = 0.63 | f1 = 0.496\n",
      "Порог = 0.64 | f1 = 0.490\n",
      "Порог = 0.64 | f1 = 0.488\n",
      "Порог = 0.65 | f1 = 0.485\n",
      "Порог = 0.65 | f1 = 0.479\n",
      "Порог = 0.66 | f1 = 0.480\n",
      "Порог = 0.66 | f1 = 0.476\n",
      "Порог = 0.67 | f1 = 0.475\n",
      "Порог = 0.67 | f1 = 0.461\n",
      "Порог = 0.68 | f1 = 0.458\n",
      "Порог = 0.68 | f1 = 0.456\n",
      "Порог = 0.69 | f1 = 0.450\n",
      "Порог = 0.69 | f1 = 0.447\n",
      "Порог = 0.70 | f1 = 0.435\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "best_roc = 0\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.005):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_val = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Порог = {:.2f} | f1 = {:.3f}\".format(\n",
    "        threshold, f1_score_val))\n",
    "    if best_f1 < f1_score_val:\n",
    "        best_threshold = threshold\n",
    "        best_f1 = f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score: 0.5010845986984815 ,\n",
      "best threshold : 0.615\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score: {} ,\\nbest threshold : {}'.format(best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследуем `2-ю модель (Дерево решений)`\n",
    "\n",
    "Подбираем оптимальную модель перебирая гиперпараметры, в данном случае max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.4994903160040775\n",
      "max_depth = 2 : 0.541015625\n",
      "max_depth = 3 : 0.541015625\n",
      "max_depth = 4 : 0.5277777777777778\n",
      "max_depth = 5 : 0.5963791267305644\n",
      "max_depth = 6 : 0.5574387947269304\n",
      "max_depth = 7 : 0.5443786982248521\n",
      "max_depth = 8 : 0.5365853658536586\n",
      "max_depth = 9 : 0.5326829268292683\n",
      "max_depth = 10 : 0.5126760563380283\n",
      "max_depth = 11 : 0.5431841831425599\n",
      "max_depth = 12 : 0.5145145145145146\n",
      "max_depth = 13 : 0.5197860962566844\n",
      "max_depth = 14 : 0.4988814317673378\n",
      "max_depth = 15 : 0.4965675057208238\n",
      "max_depth = 16 : 0.485981308411215\n",
      "max_depth = 17 : 0.4844868735083532\n",
      "max_depth = 18 : 0.4914841849148419\n",
      "max_depth = 19 : 0.48375451263537905\n"
     ]
    }
   ],
   "source": [
    "best_res = 0\n",
    "best_model = None\n",
    "for i in range(1,20):\n",
    "    model = DecisionTreeClassifier(random_state = 12345,max_depth=i, class_weight='balanced')\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    res = f1_score(target_valid, predictions)\n",
    "    print('max_depth = {} :'.format(i), res)\n",
    "    if res > best_res:\n",
    "        best_res = res\n",
    "        best_model = model\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = 0.5963791267305644\n",
      "roc_auc_score = 0.8310244134068074\n"
     ]
    }
   ],
   "source": [
    "predict_valid = best_model.predict(features_valid)\n",
    "probabilities_one_valid = best_model.predict_proba(features_valid)[:,1]\n",
    "print('f1_score =',f1_score(target_valid, predict_valid))\n",
    "print('roc_auc_score =',roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом значения метрики уже удовлетворяет условиям задачи но посмотрим еще на другие методы, может найдем что-то получше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmp4yask5cm/model.joblib.decision.tree.weight']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_decision_tree_weighted = os.path.join(save_dir, 'model.joblib.decision.tree.weight')\n",
    "joblib.dump(best_model, filename_decision_tree_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | f1 = 0.345\n",
      "Порог = 0.01 | f1 = 0.345\n",
      "Порог = 0.01 | f1 = 0.345\n",
      "Порог = 0.01 | f1 = 0.345\n",
      "Порог = 0.02 | f1 = 0.345\n",
      "Порог = 0.03 | f1 = 0.345\n",
      "Порог = 0.03 | f1 = 0.383\n",
      "Порог = 0.04 | f1 = 0.383\n",
      "Порог = 0.04 | f1 = 0.383\n",
      "Порог = 0.04 | f1 = 0.383\n",
      "Порог = 0.05 | f1 = 0.383\n",
      "Порог = 0.06 | f1 = 0.383\n",
      "Порог = 0.06 | f1 = 0.383\n",
      "Порог = 0.07 | f1 = 0.383\n",
      "Порог = 0.07 | f1 = 0.383\n",
      "Порог = 0.07 | f1 = 0.383\n",
      "Порог = 0.08 | f1 = 0.383\n",
      "Порог = 0.09 | f1 = 0.383\n",
      "Порог = 0.09 | f1 = 0.383\n",
      "Порог = 0.10 | f1 = 0.383\n",
      "Порог = 0.10 | f1 = 0.383\n",
      "Порог = 0.10 | f1 = 0.383\n",
      "Порог = 0.11 | f1 = 0.383\n",
      "Порог = 0.12 | f1 = 0.383\n",
      "Порог = 0.12 | f1 = 0.383\n",
      "Порог = 0.12 | f1 = 0.401\n",
      "Порог = 0.13 | f1 = 0.401\n",
      "Порог = 0.14 | f1 = 0.401\n",
      "Порог = 0.14 | f1 = 0.401\n",
      "Порог = 0.14 | f1 = 0.401\n",
      "Порог = 0.15 | f1 = 0.401\n",
      "Порог = 0.15 | f1 = 0.401\n",
      "Порог = 0.16 | f1 = 0.412\n",
      "Порог = 0.17 | f1 = 0.413\n",
      "Порог = 0.17 | f1 = 0.413\n",
      "Порог = 0.18 | f1 = 0.413\n",
      "Порог = 0.18 | f1 = 0.413\n",
      "Порог = 0.18 | f1 = 0.413\n",
      "Порог = 0.19 | f1 = 0.413\n",
      "Порог = 0.20 | f1 = 0.448\n",
      "Порог = 0.20 | f1 = 0.448\n",
      "Порог = 0.21 | f1 = 0.448\n",
      "Порог = 0.21 | f1 = 0.448\n",
      "Порог = 0.21 | f1 = 0.448\n",
      "Порог = 0.22 | f1 = 0.448\n",
      "Порог = 0.23 | f1 = 0.448\n",
      "Порог = 0.23 | f1 = 0.448\n",
      "Порог = 0.24 | f1 = 0.448\n",
      "Порог = 0.24 | f1 = 0.448\n",
      "Порог = 0.24 | f1 = 0.485\n",
      "Порог = 0.25 | f1 = 0.485\n",
      "Порог = 0.26 | f1 = 0.485\n",
      "Порог = 0.26 | f1 = 0.485\n",
      "Порог = 0.27 | f1 = 0.485\n",
      "Порог = 0.27 | f1 = 0.485\n",
      "Порог = 0.28 | f1 = 0.485\n",
      "Порог = 0.28 | f1 = 0.485\n",
      "Порог = 0.29 | f1 = 0.485\n",
      "Порог = 0.29 | f1 = 0.485\n",
      "Порог = 0.29 | f1 = 0.485\n",
      "Порог = 0.30 | f1 = 0.485\n",
      "Порог = 0.30 | f1 = 0.485\n",
      "Порог = 0.31 | f1 = 0.485\n",
      "Порог = 0.32 | f1 = 0.485\n",
      "Порог = 0.32 | f1 = 0.485\n",
      "Порог = 0.33 | f1 = 0.485\n",
      "Порог = 0.33 | f1 = 0.485\n",
      "Порог = 0.34 | f1 = 0.485\n",
      "Порог = 0.34 | f1 = 0.485\n",
      "Порог = 0.35 | f1 = 0.485\n",
      "Порог = 0.35 | f1 = 0.485\n",
      "Порог = 0.35 | f1 = 0.485\n",
      "Порог = 0.36 | f1 = 0.507\n",
      "Порог = 0.36 | f1 = 0.507\n",
      "Порог = 0.37 | f1 = 0.507\n",
      "Порог = 0.38 | f1 = 0.507\n",
      "Порог = 0.38 | f1 = 0.507\n",
      "Порог = 0.39 | f1 = 0.507\n",
      "Порог = 0.39 | f1 = 0.507\n",
      "Порог = 0.40 | f1 = 0.507\n",
      "Порог = 0.40 | f1 = 0.507\n",
      "Порог = 0.41 | f1 = 0.507\n",
      "Порог = 0.41 | f1 = 0.507\n",
      "Порог = 0.42 | f1 = 0.507\n",
      "Порог = 0.42 | f1 = 0.507\n",
      "Порог = 0.42 | f1 = 0.515\n",
      "Порог = 0.43 | f1 = 0.515\n",
      "Порог = 0.43 | f1 = 0.515\n",
      "Порог = 0.44 | f1 = 0.535\n",
      "Порог = 0.45 | f1 = 0.535\n",
      "Порог = 0.45 | f1 = 0.533\n",
      "Порог = 0.46 | f1 = 0.533\n",
      "Порог = 0.46 | f1 = 0.596\n",
      "Порог = 0.47 | f1 = 0.596\n",
      "Порог = 0.47 | f1 = 0.596\n",
      "Порог = 0.48 | f1 = 0.596\n",
      "Порог = 0.48 | f1 = 0.596\n",
      "Порог = 0.48 | f1 = 0.596\n",
      "Порог = 0.49 | f1 = 0.596\n",
      "Порог = 0.49 | f1 = 0.596\n",
      "Порог = 0.50 | f1 = 0.596\n",
      "Порог = 0.51 | f1 = 0.596\n",
      "Порог = 0.51 | f1 = 0.596\n",
      "Порог = 0.52 | f1 = 0.596\n",
      "Порог = 0.52 | f1 = 0.596\n",
      "Порог = 0.53 | f1 = 0.596\n",
      "Порог = 0.53 | f1 = 0.596\n",
      "Порог = 0.54 | f1 = 0.596\n",
      "Порог = 0.54 | f1 = 0.596\n",
      "Порог = 0.55 | f1 = 0.596\n",
      "Порог = 0.55 | f1 = 0.596\n",
      "Порог = 0.56 | f1 = 0.596\n",
      "Порог = 0.56 | f1 = 0.596\n",
      "Порог = 0.57 | f1 = 0.608\n",
      "Порог = 0.57 | f1 = 0.608\n",
      "Порог = 0.58 | f1 = 0.608\n",
      "Порог = 0.58 | f1 = 0.608\n",
      "Порог = 0.58 | f1 = 0.608\n",
      "Порог = 0.59 | f1 = 0.608\n",
      "Порог = 0.59 | f1 = 0.608\n",
      "Порог = 0.60 | f1 = 0.608\n",
      "Порог = 0.60 | f1 = 0.608\n",
      "Порог = 0.61 | f1 = 0.608\n",
      "Порог = 0.61 | f1 = 0.608\n",
      "Порог = 0.62 | f1 = 0.608\n",
      "Порог = 0.62 | f1 = 0.608\n",
      "Порог = 0.63 | f1 = 0.608\n",
      "Порог = 0.64 | f1 = 0.608\n",
      "Порог = 0.64 | f1 = 0.608\n",
      "Порог = 0.65 | f1 = 0.608\n",
      "Порог = 0.65 | f1 = 0.608\n",
      "Порог = 0.66 | f1 = 0.608\n",
      "Порог = 0.66 | f1 = 0.608\n",
      "Порог = 0.67 | f1 = 0.605\n",
      "Порог = 0.67 | f1 = 0.605\n",
      "Порог = 0.68 | f1 = 0.605\n",
      "Порог = 0.68 | f1 = 0.557\n",
      "Порог = 0.69 | f1 = 0.557\n",
      "Порог = 0.69 | f1 = 0.557\n",
      "Порог = 0.70 | f1 = 0.557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "model = DecisionTreeClassifier(random_state=12345, max_depth=5, class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.005):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_val = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Порог = {:.2f} | f1 = {:.3f}\".format(\n",
    "        threshold, f1_score_val))\n",
    "    if best_f1 < f1_score_val:\n",
    "        best_threshold = threshold\n",
    "        best_f1 = f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score: 0.6082004555808656 ,\n",
      "best threshold : 0.5650000000000001\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score: {} ,\\nbest threshold : {}'.format(best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исследуем `3-ю модель (Случайный лес)`\n",
    "\n",
    "Подбираем оптимальную модель перебирая гиперпараметры, в данном случае `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_estimator = 1 : 0.49017341040462425\n",
      "number_estimator = 2 : 0.4422110552763819\n",
      "number_estimator = 3 : 0.5347593582887701\n",
      "number_estimator = 4 : 0.48064516129032253\n",
      "number_estimator = 5 : 0.5505617977528091\n",
      "number_estimator = 6 : 0.514820592823713\n",
      "number_estimator = 7 : 0.5538020086083213\n",
      "number_estimator = 8 : 0.5217391304347826\n",
      "number_estimator = 9 : 0.5552325581395349\n",
      "number_estimator = 10 : 0.5292307692307692\n",
      "number_estimator = 11 : 0.5617647058823529\n",
      "number_estimator = 12 : 0.5421133231240429\n",
      "number_estimator = 13 : 0.5494830132939438\n",
      "number_estimator = 14 : 0.5292307692307692\n",
      "number_estimator = 15 : 0.5446428571428572\n",
      "number_estimator = 16 : 0.5273010920436817\n",
      "number_estimator = 17 : 0.5555555555555555\n",
      "number_estimator = 18 : 0.529595015576324\n",
      "number_estimator = 19 : 0.5361445783132529\n",
      "number_estimator = 20 : 0.5271317829457365\n",
      "number_estimator = 21 : 0.5473684210526316\n",
      "number_estimator = 22 : 0.5267993874425727\n",
      "number_estimator = 23 : 0.5481927710843373\n",
      "number_estimator = 24 : 0.5378670788253478\n",
      "number_estimator = 25 : 0.5399698340874811\n",
      "number_estimator = 26 : 0.5378670788253478\n",
      "number_estimator = 27 : 0.5402124430955993\n",
      "number_estimator = 28 : 0.5360501567398119\n",
      "number_estimator = 29 : 0.5390505359877489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "best_model = None\n",
    "best_result = 0\n",
    "for est in range(1, 30):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est, class_weight='balanced') \n",
    "    model.fit(features_train, target_train) \n",
    "    predictions = model.predict(features_valid)\n",
    "    res = f1_score(target_valid, predictions) \n",
    "    print('number_estimator = {} :'.format(est), res)\n",
    "    if res > best_result:\n",
    "        best_model = model \n",
    "        best_result = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = 0.5617647058823529\n",
      "roc_auc_score = 0.8111302996025865\n"
     ]
    }
   ],
   "source": [
    "predict_valid = best_model.predict(features_valid)\n",
    "probabilities_one_valid = best_model.predict_proba(features_valid)[:,1]\n",
    "print('f1_score =',f1_score(target_valid, predict_valid))\n",
    "print('roc_auc_score =',roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmp4yask5cm/model.joblib.random.forest.weighted']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_random_forest_weighted = os.path.join(save_dir, 'model.joblib.random.forest.weighted')\n",
    "joblib.dump(best_model, filename_random_forest_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | f1 = 0.438\n",
      "Порог = 0.01 | f1 = 0.438\n",
      "Порог = 0.01 | f1 = 0.438\n",
      "Порог = 0.01 | f1 = 0.438\n",
      "Порог = 0.02 | f1 = 0.438\n",
      "Порог = 0.03 | f1 = 0.438\n",
      "Порог = 0.03 | f1 = 0.438\n",
      "Порог = 0.04 | f1 = 0.438\n",
      "Порог = 0.04 | f1 = 0.438\n",
      "Порог = 0.04 | f1 = 0.438\n",
      "Порог = 0.05 | f1 = 0.438\n",
      "Порог = 0.06 | f1 = 0.438\n",
      "Порог = 0.06 | f1 = 0.438\n",
      "Порог = 0.07 | f1 = 0.438\n",
      "Порог = 0.07 | f1 = 0.438\n",
      "Порог = 0.07 | f1 = 0.438\n",
      "Порог = 0.08 | f1 = 0.438\n",
      "Порог = 0.09 | f1 = 0.438\n",
      "Порог = 0.09 | f1 = 0.438\n",
      "Порог = 0.10 | f1 = 0.505\n",
      "Порог = 0.10 | f1 = 0.505\n",
      "Порог = 0.10 | f1 = 0.505\n",
      "Порог = 0.11 | f1 = 0.505\n",
      "Порог = 0.12 | f1 = 0.505\n",
      "Порог = 0.12 | f1 = 0.505\n",
      "Порог = 0.12 | f1 = 0.505\n",
      "Порог = 0.13 | f1 = 0.505\n",
      "Порог = 0.14 | f1 = 0.505\n",
      "Порог = 0.14 | f1 = 0.505\n",
      "Порог = 0.14 | f1 = 0.505\n",
      "Порог = 0.15 | f1 = 0.505\n",
      "Порог = 0.15 | f1 = 0.505\n",
      "Порог = 0.16 | f1 = 0.505\n",
      "Порог = 0.17 | f1 = 0.505\n",
      "Порог = 0.17 | f1 = 0.505\n",
      "Порог = 0.18 | f1 = 0.505\n",
      "Порог = 0.18 | f1 = 0.505\n",
      "Порог = 0.18 | f1 = 0.574\n",
      "Порог = 0.19 | f1 = 0.574\n",
      "Порог = 0.20 | f1 = 0.574\n",
      "Порог = 0.20 | f1 = 0.574\n",
      "Порог = 0.21 | f1 = 0.574\n",
      "Порог = 0.21 | f1 = 0.574\n",
      "Порог = 0.21 | f1 = 0.574\n",
      "Порог = 0.22 | f1 = 0.574\n",
      "Порог = 0.23 | f1 = 0.574\n",
      "Порог = 0.23 | f1 = 0.574\n",
      "Порог = 0.24 | f1 = 0.574\n",
      "Порог = 0.24 | f1 = 0.574\n",
      "Порог = 0.24 | f1 = 0.574\n",
      "Порог = 0.25 | f1 = 0.574\n",
      "Порог = 0.26 | f1 = 0.574\n",
      "Порог = 0.26 | f1 = 0.574\n",
      "Порог = 0.27 | f1 = 0.574\n",
      "Порог = 0.27 | f1 = 0.574\n",
      "Порог = 0.28 | f1 = 0.599\n",
      "Порог = 0.28 | f1 = 0.599\n",
      "Порог = 0.29 | f1 = 0.599\n",
      "Порог = 0.29 | f1 = 0.599\n",
      "Порог = 0.29 | f1 = 0.599\n",
      "Порог = 0.30 | f1 = 0.599\n",
      "Порог = 0.30 | f1 = 0.599\n",
      "Порог = 0.31 | f1 = 0.599\n",
      "Порог = 0.32 | f1 = 0.599\n",
      "Порог = 0.32 | f1 = 0.599\n",
      "Порог = 0.33 | f1 = 0.599\n",
      "Порог = 0.33 | f1 = 0.599\n",
      "Порог = 0.34 | f1 = 0.599\n",
      "Порог = 0.34 | f1 = 0.599\n",
      "Порог = 0.35 | f1 = 0.599\n",
      "Порог = 0.35 | f1 = 0.599\n",
      "Порог = 0.35 | f1 = 0.599\n",
      "Порог = 0.36 | f1 = 0.599\n",
      "Порог = 0.36 | f1 = 0.583\n",
      "Порог = 0.37 | f1 = 0.583\n",
      "Порог = 0.38 | f1 = 0.583\n",
      "Порог = 0.38 | f1 = 0.583\n",
      "Порог = 0.39 | f1 = 0.583\n",
      "Порог = 0.39 | f1 = 0.583\n",
      "Порог = 0.40 | f1 = 0.583\n",
      "Порог = 0.40 | f1 = 0.583\n",
      "Порог = 0.41 | f1 = 0.583\n",
      "Порог = 0.41 | f1 = 0.583\n",
      "Порог = 0.42 | f1 = 0.583\n",
      "Порог = 0.42 | f1 = 0.583\n",
      "Порог = 0.42 | f1 = 0.583\n",
      "Порог = 0.43 | f1 = 0.583\n",
      "Порог = 0.43 | f1 = 0.583\n",
      "Порог = 0.44 | f1 = 0.583\n",
      "Порог = 0.45 | f1 = 0.583\n",
      "Порог = 0.45 | f1 = 0.583\n",
      "Порог = 0.46 | f1 = 0.562\n",
      "Порог = 0.46 | f1 = 0.562\n",
      "Порог = 0.47 | f1 = 0.562\n",
      "Порог = 0.47 | f1 = 0.562\n",
      "Порог = 0.48 | f1 = 0.562\n",
      "Порог = 0.48 | f1 = 0.562\n",
      "Порог = 0.48 | f1 = 0.562\n",
      "Порог = 0.49 | f1 = 0.562\n",
      "Порог = 0.49 | f1 = 0.562\n",
      "Порог = 0.50 | f1 = 0.562\n",
      "Порог = 0.51 | f1 = 0.562\n",
      "Порог = 0.51 | f1 = 0.562\n",
      "Порог = 0.52 | f1 = 0.562\n",
      "Порог = 0.52 | f1 = 0.562\n",
      "Порог = 0.53 | f1 = 0.562\n",
      "Порог = 0.53 | f1 = 0.562\n",
      "Порог = 0.54 | f1 = 0.562\n",
      "Порог = 0.54 | f1 = 0.562\n",
      "Порог = 0.55 | f1 = 0.562\n",
      "Порог = 0.55 | f1 = 0.512\n",
      "Порог = 0.56 | f1 = 0.512\n",
      "Порог = 0.56 | f1 = 0.512\n",
      "Порог = 0.57 | f1 = 0.512\n",
      "Порог = 0.57 | f1 = 0.512\n",
      "Порог = 0.58 | f1 = 0.512\n",
      "Порог = 0.58 | f1 = 0.512\n",
      "Порог = 0.58 | f1 = 0.512\n",
      "Порог = 0.59 | f1 = 0.512\n",
      "Порог = 0.59 | f1 = 0.512\n",
      "Порог = 0.60 | f1 = 0.512\n",
      "Порог = 0.60 | f1 = 0.512\n",
      "Порог = 0.61 | f1 = 0.512\n",
      "Порог = 0.61 | f1 = 0.512\n",
      "Порог = 0.62 | f1 = 0.512\n",
      "Порог = 0.62 | f1 = 0.512\n",
      "Порог = 0.63 | f1 = 0.512\n",
      "Порог = 0.64 | f1 = 0.512\n",
      "Порог = 0.64 | f1 = 0.446\n",
      "Порог = 0.65 | f1 = 0.446\n",
      "Порог = 0.65 | f1 = 0.446\n",
      "Порог = 0.66 | f1 = 0.446\n",
      "Порог = 0.66 | f1 = 0.446\n",
      "Порог = 0.67 | f1 = 0.446\n",
      "Порог = 0.67 | f1 = 0.446\n",
      "Порог = 0.68 | f1 = 0.446\n",
      "Порог = 0.68 | f1 = 0.446\n",
      "Порог = 0.69 | f1 = 0.446\n",
      "Порог = 0.69 | f1 = 0.446\n",
      "Порог = 0.70 | f1 = 0.446\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = joblib.load(filename_random_forest_weighted).predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.005):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_val = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Порог = {:.2f} | f1 = {:.3f}\".format(\n",
    "        threshold, f1_score_val))\n",
    "    if best_f1 < f1_score_val:\n",
    "        best_threshold = threshold\n",
    "        best_f1 = f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score: 0.5990888382687928 ,\n",
      "best threshold : 0.275\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score: {} ,\\nbest threshold : {}'.format(best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытаемся применить **второй метод борьбы с дисбалансом** а именно `upsampling`, т.е мы будем искуственно увеличивать размер выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теперь применяем полученные данные для обучения `1-ой модели (логистическая регрессия)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4888507718696398\n",
      "roc_auc_score = 0.763109503444855\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled,target_upsampled) \n",
    "predict_valid = model.predict(features_valid)\n",
    "probabilities_one_valid = model.predict_proba(features_valid)[:,1]\n",
    "\n",
    "print(f1_score(target_valid, predict_valid))\n",
    "print('roc_auc_score =',roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmp4yask5cm/model.joblib.log.reg.up']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_logistic_reg_upsampling = os.path.join(save_dir, 'model.joblib.log.reg.up')\n",
    "joblib.dump(model, filename_logistic_reg_upsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | f1 = 0.346\n",
      "Порог = 0.01 | f1 = 0.346\n",
      "Порог = 0.01 | f1 = 0.346\n",
      "Порог = 0.01 | f1 = 0.346\n",
      "Порог = 0.02 | f1 = 0.346\n",
      "Порог = 0.03 | f1 = 0.346\n",
      "Порог = 0.03 | f1 = 0.346\n",
      "Порог = 0.04 | f1 = 0.346\n",
      "Порог = 0.04 | f1 = 0.346\n",
      "Порог = 0.04 | f1 = 0.346\n",
      "Порог = 0.05 | f1 = 0.346\n",
      "Порог = 0.06 | f1 = 0.347\n",
      "Порог = 0.06 | f1 = 0.347\n",
      "Порог = 0.07 | f1 = 0.347\n",
      "Порог = 0.07 | f1 = 0.348\n",
      "Порог = 0.07 | f1 = 0.349\n",
      "Порог = 0.08 | f1 = 0.349\n",
      "Порог = 0.09 | f1 = 0.351\n",
      "Порог = 0.09 | f1 = 0.352\n",
      "Порог = 0.10 | f1 = 0.353\n",
      "Порог = 0.10 | f1 = 0.354\n",
      "Порог = 0.10 | f1 = 0.356\n",
      "Порог = 0.11 | f1 = 0.358\n",
      "Порог = 0.12 | f1 = 0.358\n",
      "Порог = 0.12 | f1 = 0.359\n",
      "Порог = 0.12 | f1 = 0.362\n",
      "Порог = 0.13 | f1 = 0.364\n",
      "Порог = 0.14 | f1 = 0.366\n",
      "Порог = 0.14 | f1 = 0.368\n",
      "Порог = 0.14 | f1 = 0.369\n",
      "Порог = 0.15 | f1 = 0.371\n",
      "Порог = 0.15 | f1 = 0.373\n",
      "Порог = 0.16 | f1 = 0.375\n",
      "Порог = 0.17 | f1 = 0.377\n",
      "Порог = 0.17 | f1 = 0.377\n",
      "Порог = 0.18 | f1 = 0.379\n",
      "Порог = 0.18 | f1 = 0.379\n",
      "Порог = 0.18 | f1 = 0.380\n",
      "Порог = 0.19 | f1 = 0.381\n",
      "Порог = 0.20 | f1 = 0.383\n",
      "Порог = 0.20 | f1 = 0.388\n",
      "Порог = 0.21 | f1 = 0.392\n",
      "Порог = 0.21 | f1 = 0.393\n",
      "Порог = 0.21 | f1 = 0.394\n",
      "Порог = 0.22 | f1 = 0.397\n",
      "Порог = 0.23 | f1 = 0.397\n",
      "Порог = 0.23 | f1 = 0.398\n",
      "Порог = 0.24 | f1 = 0.399\n",
      "Порог = 0.24 | f1 = 0.402\n",
      "Порог = 0.24 | f1 = 0.402\n",
      "Порог = 0.25 | f1 = 0.404\n",
      "Порог = 0.26 | f1 = 0.406\n",
      "Порог = 0.26 | f1 = 0.408\n",
      "Порог = 0.27 | f1 = 0.412\n",
      "Порог = 0.27 | f1 = 0.413\n",
      "Порог = 0.28 | f1 = 0.415\n",
      "Порог = 0.28 | f1 = 0.417\n",
      "Порог = 0.29 | f1 = 0.417\n",
      "Порог = 0.29 | f1 = 0.417\n",
      "Порог = 0.29 | f1 = 0.418\n",
      "Порог = 0.30 | f1 = 0.423\n",
      "Порог = 0.30 | f1 = 0.426\n",
      "Порог = 0.31 | f1 = 0.430\n",
      "Порог = 0.32 | f1 = 0.432\n",
      "Порог = 0.32 | f1 = 0.432\n",
      "Порог = 0.33 | f1 = 0.435\n",
      "Порог = 0.33 | f1 = 0.437\n",
      "Порог = 0.34 | f1 = 0.439\n",
      "Порог = 0.34 | f1 = 0.441\n",
      "Порог = 0.35 | f1 = 0.442\n",
      "Порог = 0.35 | f1 = 0.447\n",
      "Порог = 0.35 | f1 = 0.450\n",
      "Порог = 0.36 | f1 = 0.453\n",
      "Порог = 0.36 | f1 = 0.454\n",
      "Порог = 0.37 | f1 = 0.458\n",
      "Порог = 0.38 | f1 = 0.460\n",
      "Порог = 0.38 | f1 = 0.463\n",
      "Порог = 0.39 | f1 = 0.466\n",
      "Порог = 0.39 | f1 = 0.469\n",
      "Порог = 0.40 | f1 = 0.474\n",
      "Порог = 0.40 | f1 = 0.470\n",
      "Порог = 0.41 | f1 = 0.475\n",
      "Порог = 0.41 | f1 = 0.474\n",
      "Порог = 0.42 | f1 = 0.475\n",
      "Порог = 0.42 | f1 = 0.474\n",
      "Порог = 0.42 | f1 = 0.474\n",
      "Порог = 0.43 | f1 = 0.479\n",
      "Порог = 0.43 | f1 = 0.480\n",
      "Порог = 0.44 | f1 = 0.485\n",
      "Порог = 0.45 | f1 = 0.487\n",
      "Порог = 0.45 | f1 = 0.483\n",
      "Порог = 0.46 | f1 = 0.487\n",
      "Порог = 0.46 | f1 = 0.483\n",
      "Порог = 0.47 | f1 = 0.483\n",
      "Порог = 0.47 | f1 = 0.483\n",
      "Порог = 0.48 | f1 = 0.484\n",
      "Порог = 0.48 | f1 = 0.485\n",
      "Порог = 0.48 | f1 = 0.484\n",
      "Порог = 0.49 | f1 = 0.486\n",
      "Порог = 0.49 | f1 = 0.488\n",
      "Порог = 0.50 | f1 = 0.489\n",
      "Порог = 0.51 | f1 = 0.490\n",
      "Порог = 0.51 | f1 = 0.490\n",
      "Порог = 0.52 | f1 = 0.492\n",
      "Порог = 0.52 | f1 = 0.493\n",
      "Порог = 0.53 | f1 = 0.496\n",
      "Порог = 0.53 | f1 = 0.496\n",
      "Порог = 0.54 | f1 = 0.500\n",
      "Порог = 0.54 | f1 = 0.497\n",
      "Порог = 0.55 | f1 = 0.499\n",
      "Порог = 0.55 | f1 = 0.500\n",
      "Порог = 0.56 | f1 = 0.496\n",
      "Порог = 0.56 | f1 = 0.493\n",
      "Порог = 0.57 | f1 = 0.491\n",
      "Порог = 0.57 | f1 = 0.495\n",
      "Порог = 0.58 | f1 = 0.495\n",
      "Порог = 0.58 | f1 = 0.493\n",
      "Порог = 0.58 | f1 = 0.493\n",
      "Порог = 0.59 | f1 = 0.491\n",
      "Порог = 0.59 | f1 = 0.488\n",
      "Порог = 0.60 | f1 = 0.489\n",
      "Порог = 0.60 | f1 = 0.489\n",
      "Порог = 0.61 | f1 = 0.496\n",
      "Порог = 0.61 | f1 = 0.500\n",
      "Порог = 0.62 | f1 = 0.500\n",
      "Порог = 0.62 | f1 = 0.495\n",
      "Порог = 0.63 | f1 = 0.493\n",
      "Порог = 0.64 | f1 = 0.489\n",
      "Порог = 0.64 | f1 = 0.488\n",
      "Порог = 0.65 | f1 = 0.485\n",
      "Порог = 0.65 | f1 = 0.480\n",
      "Порог = 0.66 | f1 = 0.479\n",
      "Порог = 0.66 | f1 = 0.477\n",
      "Порог = 0.67 | f1 = 0.471\n",
      "Порог = 0.67 | f1 = 0.462\n",
      "Порог = 0.68 | f1 = 0.456\n",
      "Порог = 0.68 | f1 = 0.454\n",
      "Порог = 0.69 | f1 = 0.450\n",
      "Порог = 0.69 | f1 = 0.444\n",
      "Порог = 0.70 | f1 = 0.433\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = joblib.load(filename_logistic_reg_upsampling).predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.005):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_val = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Порог = {:.2f} | f1 = {:.3f}\".format(\n",
    "        threshold, f1_score_val))\n",
    "    if best_f1 < f1_score_val:\n",
    "        best_threshold = threshold\n",
    "        best_f1 = f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score: 0.5000000000000001 ,\n",
      "best threshold : 0.62\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score: {} ,\\nbest threshold : {}'.format(best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теперь применяем полученные данные для обучения `2-ой модели (Дерево решений)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.4994903160040775\n",
      "max_depth = 2 : 0.541015625\n",
      "max_depth = 3 : 0.541015625\n",
      "max_depth = 4 : 0.5277777777777778\n",
      "max_depth = 5 : 0.5963791267305644\n",
      "max_depth = 6 : 0.5574387947269304\n",
      "max_depth = 7 : 0.5454545454545454\n",
      "max_depth = 8 : 0.5385365853658537\n",
      "max_depth = 9 : 0.5317693059628543\n",
      "max_depth = 10 : 0.5141776937618148\n",
      "max_depth = 11 : 0.5412748171368861\n",
      "max_depth = 12 : 0.5112474437627812\n",
      "max_depth = 13 : 0.5146579804560261\n",
      "max_depth = 14 : 0.4971751412429378\n",
      "max_depth = 15 : 0.502262443438914\n",
      "max_depth = 16 : 0.5\n",
      "max_depth = 17 : 0.49467455621301776\n",
      "max_depth = 18 : 0.4929245283018868\n",
      "max_depth = 19 : 0.47086801426872776\n"
     ]
    }
   ],
   "source": [
    "best_res = 0\n",
    "best_model = None\n",
    "for i in range(1,20):\n",
    "    model = DecisionTreeClassifier(random_state = 12345,max_depth=i)\n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    predictions = model.predict(features_valid)\n",
    "    res = f1_score(target_valid, predictions)\n",
    "    print('max_depth = {} :'.format(i), res)\n",
    "    if res > best_res:\n",
    "        best_res = res\n",
    "        best_model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = 0.5963791267305644\n",
      "roc_auc_score = 0.8310244134068074\n"
     ]
    }
   ],
   "source": [
    "predict_valid = best_model.predict(features_valid)\n",
    "probabilities_one_valid = best_model.predict_proba(features_valid)[:,1]\n",
    "print('f1_score =',f1_score(target_valid, predict_valid))\n",
    "print('roc_auc_score =',roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmp4yask5cm/model.joblib.decision_tree.up']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_decision_tree_upsample = os.path.join(save_dir, 'model.joblib.decision_tree.up')\n",
    "joblib.dump(best_model, filename_decision_tree_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | f1 = 0.345\n",
      "Порог = 0.01 | f1 = 0.345\n",
      "Порог = 0.01 | f1 = 0.345\n",
      "Порог = 0.01 | f1 = 0.345\n",
      "Порог = 0.02 | f1 = 0.345\n",
      "Порог = 0.03 | f1 = 0.345\n",
      "Порог = 0.03 | f1 = 0.383\n",
      "Порог = 0.04 | f1 = 0.383\n",
      "Порог = 0.04 | f1 = 0.383\n",
      "Порог = 0.04 | f1 = 0.383\n",
      "Порог = 0.05 | f1 = 0.383\n",
      "Порог = 0.06 | f1 = 0.383\n",
      "Порог = 0.06 | f1 = 0.383\n",
      "Порог = 0.07 | f1 = 0.383\n",
      "Порог = 0.07 | f1 = 0.383\n",
      "Порог = 0.07 | f1 = 0.383\n",
      "Порог = 0.08 | f1 = 0.383\n",
      "Порог = 0.09 | f1 = 0.383\n",
      "Порог = 0.09 | f1 = 0.383\n",
      "Порог = 0.10 | f1 = 0.383\n",
      "Порог = 0.10 | f1 = 0.383\n",
      "Порог = 0.10 | f1 = 0.383\n",
      "Порог = 0.11 | f1 = 0.383\n",
      "Порог = 0.12 | f1 = 0.383\n",
      "Порог = 0.12 | f1 = 0.383\n",
      "Порог = 0.12 | f1 = 0.401\n",
      "Порог = 0.13 | f1 = 0.401\n",
      "Порог = 0.14 | f1 = 0.401\n",
      "Порог = 0.14 | f1 = 0.401\n",
      "Порог = 0.14 | f1 = 0.401\n",
      "Порог = 0.15 | f1 = 0.401\n",
      "Порог = 0.15 | f1 = 0.401\n",
      "Порог = 0.16 | f1 = 0.412\n",
      "Порог = 0.17 | f1 = 0.413\n",
      "Порог = 0.17 | f1 = 0.413\n",
      "Порог = 0.18 | f1 = 0.413\n",
      "Порог = 0.18 | f1 = 0.413\n",
      "Порог = 0.18 | f1 = 0.413\n",
      "Порог = 0.19 | f1 = 0.413\n",
      "Порог = 0.20 | f1 = 0.448\n",
      "Порог = 0.20 | f1 = 0.448\n",
      "Порог = 0.21 | f1 = 0.448\n",
      "Порог = 0.21 | f1 = 0.448\n",
      "Порог = 0.21 | f1 = 0.448\n",
      "Порог = 0.22 | f1 = 0.448\n",
      "Порог = 0.23 | f1 = 0.448\n",
      "Порог = 0.23 | f1 = 0.448\n",
      "Порог = 0.24 | f1 = 0.448\n",
      "Порог = 0.24 | f1 = 0.448\n",
      "Порог = 0.24 | f1 = 0.485\n",
      "Порог = 0.25 | f1 = 0.485\n",
      "Порог = 0.26 | f1 = 0.485\n",
      "Порог = 0.26 | f1 = 0.485\n",
      "Порог = 0.27 | f1 = 0.485\n",
      "Порог = 0.27 | f1 = 0.485\n",
      "Порог = 0.28 | f1 = 0.485\n",
      "Порог = 0.28 | f1 = 0.485\n",
      "Порог = 0.29 | f1 = 0.485\n",
      "Порог = 0.29 | f1 = 0.485\n",
      "Порог = 0.29 | f1 = 0.485\n",
      "Порог = 0.30 | f1 = 0.485\n",
      "Порог = 0.30 | f1 = 0.485\n",
      "Порог = 0.31 | f1 = 0.485\n",
      "Порог = 0.32 | f1 = 0.485\n",
      "Порог = 0.32 | f1 = 0.485\n",
      "Порог = 0.33 | f1 = 0.485\n",
      "Порог = 0.33 | f1 = 0.485\n",
      "Порог = 0.34 | f1 = 0.485\n",
      "Порог = 0.34 | f1 = 0.485\n",
      "Порог = 0.35 | f1 = 0.485\n",
      "Порог = 0.35 | f1 = 0.485\n",
      "Порог = 0.35 | f1 = 0.507\n",
      "Порог = 0.36 | f1 = 0.507\n",
      "Порог = 0.36 | f1 = 0.507\n",
      "Порог = 0.37 | f1 = 0.507\n",
      "Порог = 0.38 | f1 = 0.507\n",
      "Порог = 0.38 | f1 = 0.507\n",
      "Порог = 0.39 | f1 = 0.507\n",
      "Порог = 0.39 | f1 = 0.507\n",
      "Порог = 0.40 | f1 = 0.507\n",
      "Порог = 0.40 | f1 = 0.507\n",
      "Порог = 0.41 | f1 = 0.507\n",
      "Порог = 0.41 | f1 = 0.507\n",
      "Порог = 0.42 | f1 = 0.507\n",
      "Порог = 0.42 | f1 = 0.507\n",
      "Порог = 0.42 | f1 = 0.515\n",
      "Порог = 0.43 | f1 = 0.515\n",
      "Порог = 0.43 | f1 = 0.515\n",
      "Порог = 0.44 | f1 = 0.535\n",
      "Порог = 0.45 | f1 = 0.533\n",
      "Порог = 0.45 | f1 = 0.533\n",
      "Порог = 0.46 | f1 = 0.596\n",
      "Порог = 0.46 | f1 = 0.596\n",
      "Порог = 0.47 | f1 = 0.596\n",
      "Порог = 0.47 | f1 = 0.596\n",
      "Порог = 0.48 | f1 = 0.596\n",
      "Порог = 0.48 | f1 = 0.596\n",
      "Порог = 0.48 | f1 = 0.596\n",
      "Порог = 0.49 | f1 = 0.596\n",
      "Порог = 0.49 | f1 = 0.596\n",
      "Порог = 0.50 | f1 = 0.596\n",
      "Порог = 0.51 | f1 = 0.596\n",
      "Порог = 0.51 | f1 = 0.596\n",
      "Порог = 0.52 | f1 = 0.596\n",
      "Порог = 0.52 | f1 = 0.596\n",
      "Порог = 0.53 | f1 = 0.596\n",
      "Порог = 0.53 | f1 = 0.596\n",
      "Порог = 0.54 | f1 = 0.596\n",
      "Порог = 0.54 | f1 = 0.596\n",
      "Порог = 0.55 | f1 = 0.596\n",
      "Порог = 0.55 | f1 = 0.596\n",
      "Порог = 0.56 | f1 = 0.596\n",
      "Порог = 0.56 | f1 = 0.596\n",
      "Порог = 0.57 | f1 = 0.608\n",
      "Порог = 0.57 | f1 = 0.608\n",
      "Порог = 0.58 | f1 = 0.608\n",
      "Порог = 0.58 | f1 = 0.608\n",
      "Порог = 0.58 | f1 = 0.608\n",
      "Порог = 0.59 | f1 = 0.608\n",
      "Порог = 0.59 | f1 = 0.608\n",
      "Порог = 0.60 | f1 = 0.608\n",
      "Порог = 0.60 | f1 = 0.608\n",
      "Порог = 0.61 | f1 = 0.608\n",
      "Порог = 0.61 | f1 = 0.608\n",
      "Порог = 0.62 | f1 = 0.608\n",
      "Порог = 0.62 | f1 = 0.608\n",
      "Порог = 0.63 | f1 = 0.608\n",
      "Порог = 0.64 | f1 = 0.608\n",
      "Порог = 0.64 | f1 = 0.608\n",
      "Порог = 0.65 | f1 = 0.608\n",
      "Порог = 0.65 | f1 = 0.608\n",
      "Порог = 0.66 | f1 = 0.608\n",
      "Порог = 0.66 | f1 = 0.608\n",
      "Порог = 0.67 | f1 = 0.605\n",
      "Порог = 0.67 | f1 = 0.605\n",
      "Порог = 0.68 | f1 = 0.557\n",
      "Порог = 0.68 | f1 = 0.557\n",
      "Порог = 0.69 | f1 = 0.557\n",
      "Порог = 0.69 | f1 = 0.557\n",
      "Порог = 0.70 | f1 = 0.557\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = joblib.load(filename_decision_tree_upsample).predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.005):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_val = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Порог = {:.2f} | f1 = {:.3f}\".format(\n",
    "        threshold, f1_score_val))\n",
    "    if best_f1 < f1_score_val:\n",
    "        best_threshold = threshold\n",
    "        best_f1 = f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score: 0.6082004555808656 ,\n",
      "best threshold : 0.5650000000000001\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score: {} ,\\nbest threshold : {}'.format(best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теперь применяем полученные данные для обучения 3-ей модели (Дерево решений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_estimator = 1 : 0.4878587196467991\n",
      "number_estimator = 2 : 0.42771084337349397\n",
      "number_estimator = 3 : 0.540410132689988\n",
      "number_estimator = 4 : 0.5354107648725213\n",
      "number_estimator = 5 : 0.5738916256157636\n",
      "number_estimator = 6 : 0.5596707818930041\n",
      "number_estimator = 7 : 0.5808080808080809\n",
      "number_estimator = 8 : 0.5953991880920162\n",
      "number_estimator = 9 : 0.6038216560509554\n",
      "number_estimator = 10 : 0.5959183673469388\n",
      "number_estimator = 11 : 0.6051282051282051\n",
      "number_estimator = 12 : 0.6054054054054053\n",
      "number_estimator = 13 : 0.6010230179028133\n",
      "number_estimator = 14 : 0.5978552278820375\n",
      "number_estimator = 15 : 0.6090322580645161\n",
      "number_estimator = 16 : 0.6037735849056604\n",
      "number_estimator = 17 : 0.6030927835051547\n",
      "number_estimator = 18 : 0.6002691790040375\n",
      "number_estimator = 19 : 0.6049543676662321\n",
      "number_estimator = 20 : 0.6099865047233469\n",
      "number_estimator = 21 : 0.6093750000000001\n",
      "number_estimator = 22 : 0.5972972972972973\n",
      "number_estimator = 23 : 0.6020942408376964\n",
      "number_estimator = 24 : 0.5964912280701755\n",
      "number_estimator = 25 : 0.5950196592398428\n",
      "number_estimator = 26 : 0.5983827493261457\n",
      "number_estimator = 27 : 0.6013071895424836\n",
      "number_estimator = 28 : 0.6029609690444145\n",
      "number_estimator = 29 : 0.607095926412615\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "for est in range(1, 30):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est) \n",
    "    model.fit(features_upsampled, target_upsampled) \n",
    "    predictions = model.predict(features_valid)\n",
    "    res = f1_score(target_valid, predictions) \n",
    "    print('number_estimator = {} :'.format(est), res)\n",
    "    if res > best_result:\n",
    "        best_model = model \n",
    "        best_result = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = 0.6099865047233469\n",
      "roc_auc_score = 0.8250397715931017\n"
     ]
    }
   ],
   "source": [
    "predict_valid = best_model.predict(features_valid)\n",
    "probabilities_one_valid = best_model.predict_proba(features_valid)[:,1]\n",
    "print('f1_score =',f1_score(target_valid, predict_valid))\n",
    "print('roc_auc_score =',roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/tmp4yask5cm/model.joblib.random_forest.up']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_random_forest_upsample = os.path.join(save_dir, 'model.joblib.random_forest.up')\n",
    "joblib.dump(best_model, filename_random_forest_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | f1 = 0.394\n",
      "Порог = 0.01 | f1 = 0.394\n",
      "Порог = 0.01 | f1 = 0.394\n",
      "Порог = 0.01 | f1 = 0.394\n",
      "Порог = 0.02 | f1 = 0.394\n",
      "Порог = 0.03 | f1 = 0.394\n",
      "Порог = 0.03 | f1 = 0.394\n",
      "Порог = 0.04 | f1 = 0.394\n",
      "Порог = 0.04 | f1 = 0.394\n",
      "Порог = 0.04 | f1 = 0.394\n",
      "Порог = 0.05 | f1 = 0.431\n",
      "Порог = 0.06 | f1 = 0.431\n",
      "Порог = 0.06 | f1 = 0.431\n",
      "Порог = 0.07 | f1 = 0.431\n",
      "Порог = 0.07 | f1 = 0.431\n",
      "Порог = 0.07 | f1 = 0.431\n",
      "Порог = 0.08 | f1 = 0.431\n",
      "Порог = 0.09 | f1 = 0.431\n",
      "Порог = 0.09 | f1 = 0.431\n",
      "Порог = 0.10 | f1 = 0.431\n",
      "Порог = 0.10 | f1 = 0.469\n",
      "Порог = 0.10 | f1 = 0.469\n",
      "Порог = 0.11 | f1 = 0.469\n",
      "Порог = 0.12 | f1 = 0.469\n",
      "Порог = 0.12 | f1 = 0.469\n",
      "Порог = 0.12 | f1 = 0.469\n",
      "Порог = 0.13 | f1 = 0.469\n",
      "Порог = 0.14 | f1 = 0.469\n",
      "Порог = 0.14 | f1 = 0.469\n",
      "Порог = 0.14 | f1 = 0.469\n",
      "Порог = 0.15 | f1 = 0.498\n",
      "Порог = 0.15 | f1 = 0.498\n",
      "Порог = 0.16 | f1 = 0.498\n",
      "Порог = 0.17 | f1 = 0.498\n",
      "Порог = 0.17 | f1 = 0.498\n",
      "Порог = 0.18 | f1 = 0.498\n",
      "Порог = 0.18 | f1 = 0.498\n",
      "Порог = 0.18 | f1 = 0.498\n",
      "Порог = 0.19 | f1 = 0.498\n",
      "Порог = 0.20 | f1 = 0.498\n",
      "Порог = 0.20 | f1 = 0.525\n",
      "Порог = 0.21 | f1 = 0.525\n",
      "Порог = 0.21 | f1 = 0.525\n",
      "Порог = 0.21 | f1 = 0.525\n",
      "Порог = 0.22 | f1 = 0.525\n",
      "Порог = 0.23 | f1 = 0.525\n",
      "Порог = 0.23 | f1 = 0.525\n",
      "Порог = 0.24 | f1 = 0.525\n",
      "Порог = 0.24 | f1 = 0.525\n",
      "Порог = 0.24 | f1 = 0.525\n",
      "Порог = 0.25 | f1 = 0.554\n",
      "Порог = 0.26 | f1 = 0.554\n",
      "Порог = 0.26 | f1 = 0.554\n",
      "Порог = 0.27 | f1 = 0.554\n",
      "Порог = 0.27 | f1 = 0.554\n",
      "Порог = 0.28 | f1 = 0.554\n",
      "Порог = 0.28 | f1 = 0.554\n",
      "Порог = 0.29 | f1 = 0.554\n",
      "Порог = 0.29 | f1 = 0.554\n",
      "Порог = 0.29 | f1 = 0.554\n",
      "Порог = 0.30 | f1 = 0.579\n",
      "Порог = 0.30 | f1 = 0.579\n",
      "Порог = 0.31 | f1 = 0.579\n",
      "Порог = 0.32 | f1 = 0.579\n",
      "Порог = 0.32 | f1 = 0.579\n",
      "Порог = 0.33 | f1 = 0.579\n",
      "Порог = 0.33 | f1 = 0.579\n",
      "Порог = 0.34 | f1 = 0.579\n",
      "Порог = 0.34 | f1 = 0.579\n",
      "Порог = 0.35 | f1 = 0.579\n",
      "Порог = 0.35 | f1 = 0.599\n",
      "Порог = 0.35 | f1 = 0.599\n",
      "Порог = 0.36 | f1 = 0.599\n",
      "Порог = 0.36 | f1 = 0.599\n",
      "Порог = 0.37 | f1 = 0.599\n",
      "Порог = 0.38 | f1 = 0.599\n",
      "Порог = 0.38 | f1 = 0.599\n",
      "Порог = 0.39 | f1 = 0.599\n",
      "Порог = 0.39 | f1 = 0.599\n",
      "Порог = 0.40 | f1 = 0.599\n",
      "Порог = 0.40 | f1 = 0.613\n",
      "Порог = 0.41 | f1 = 0.613\n",
      "Порог = 0.41 | f1 = 0.613\n",
      "Порог = 0.42 | f1 = 0.613\n",
      "Порог = 0.42 | f1 = 0.613\n",
      "Порог = 0.42 | f1 = 0.613\n",
      "Порог = 0.43 | f1 = 0.613\n",
      "Порог = 0.43 | f1 = 0.613\n",
      "Порог = 0.44 | f1 = 0.613\n",
      "Порог = 0.45 | f1 = 0.613\n",
      "Порог = 0.45 | f1 = 0.606\n",
      "Порог = 0.46 | f1 = 0.606\n",
      "Порог = 0.46 | f1 = 0.606\n",
      "Порог = 0.47 | f1 = 0.606\n",
      "Порог = 0.47 | f1 = 0.606\n",
      "Порог = 0.48 | f1 = 0.606\n",
      "Порог = 0.48 | f1 = 0.606\n",
      "Порог = 0.48 | f1 = 0.606\n",
      "Порог = 0.49 | f1 = 0.606\n",
      "Порог = 0.49 | f1 = 0.606\n",
      "Порог = 0.50 | f1 = 0.610\n",
      "Порог = 0.51 | f1 = 0.610\n",
      "Порог = 0.51 | f1 = 0.610\n",
      "Порог = 0.52 | f1 = 0.610\n",
      "Порог = 0.52 | f1 = 0.610\n",
      "Порог = 0.53 | f1 = 0.610\n",
      "Порог = 0.53 | f1 = 0.610\n",
      "Порог = 0.54 | f1 = 0.610\n",
      "Порог = 0.54 | f1 = 0.610\n",
      "Порог = 0.55 | f1 = 0.610\n",
      "Порог = 0.55 | f1 = 0.589\n",
      "Порог = 0.56 | f1 = 0.589\n",
      "Порог = 0.56 | f1 = 0.589\n",
      "Порог = 0.57 | f1 = 0.589\n",
      "Порог = 0.57 | f1 = 0.589\n",
      "Порог = 0.58 | f1 = 0.589\n",
      "Порог = 0.58 | f1 = 0.589\n",
      "Порог = 0.58 | f1 = 0.589\n",
      "Порог = 0.59 | f1 = 0.589\n",
      "Порог = 0.59 | f1 = 0.589\n",
      "Порог = 0.60 | f1 = 0.567\n",
      "Порог = 0.60 | f1 = 0.567\n",
      "Порог = 0.61 | f1 = 0.567\n",
      "Порог = 0.61 | f1 = 0.567\n",
      "Порог = 0.62 | f1 = 0.567\n",
      "Порог = 0.62 | f1 = 0.567\n",
      "Порог = 0.63 | f1 = 0.567\n",
      "Порог = 0.64 | f1 = 0.567\n",
      "Порог = 0.64 | f1 = 0.567\n",
      "Порог = 0.65 | f1 = 0.567\n",
      "Порог = 0.65 | f1 = 0.546\n",
      "Порог = 0.66 | f1 = 0.546\n",
      "Порог = 0.66 | f1 = 0.546\n",
      "Порог = 0.67 | f1 = 0.546\n",
      "Порог = 0.67 | f1 = 0.546\n",
      "Порог = 0.68 | f1 = 0.546\n",
      "Порог = 0.68 | f1 = 0.546\n",
      "Порог = 0.69 | f1 = 0.546\n",
      "Порог = 0.69 | f1 = 0.546\n",
      "Порог = 0.70 | f1 = 0.546\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = joblib.load(filename_random_forest_upsample).predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0, 0.7, 0.005):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1_score_val = f1_score(target_valid, predicted_valid)\n",
    "    print(\"Порог = {:.2f} | f1 = {:.3f}\".format(\n",
    "        threshold, f1_score_val))\n",
    "    if best_f1 < f1_score_val:\n",
    "        best_threshold = threshold\n",
    "        best_f1 = f1_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1_score: 0.6127167630057804 ,\n",
      "best threshold : 0.4\n"
     ]
    }
   ],
   "source": [
    "print('best f1_score: {} ,\\nbest threshold : {}'.format(best_f1, best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Самой лучшей моделью **в случае с применением параметра class_weight = 'balanced'**, оказался алгоритм DecisionTreeClassifier, значения f1_score и aug_roc которого оказались максимальными среди трёх представленных алгоритмов и равны соответсвенно **f1_score = 0.5963791267305644, roc_auc_score = 0.8310244134068074**, также при изменение threshold эти значения становятся чуть лучше. **В случае с upsampling-ом** лучшей моделью оказался алгоритм RandomForest, значения которого превышают DecisionTreeClassifier, и являются лучшими среди всех методов борьбы с дисбалансом и равны соответственно **f1_score = 0.609597924773022, roc_auc_score = 0.8284286742600669**. Значения f1_score в обоих случаях удовлетворяют условиям задачи, поэтому теперь стоит проверить как наша модель справляется с тестовой выборкой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем 2 лидирующие модели дабы удостовериться в лидерстве одной из них(или в их равенстве)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = df_test.drop(['exited'], axis=1)\n",
    "target_test = df_test['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обьединяю train и test для DecisionTreeClassifier, чтобы обучить ее с уже известными параметрами на обьединенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_valid =  pd.concat([features_train] + [features_valid])\n",
    "target_train_valid = pd.concat([target_train] + [target_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также создаю **upsampling** train и test, чтобы применить RandomForestClassifier, который у нас испльзуется с подобранными параметрами, но без параметра class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled_train_valid, target_upsampled_train_valid = upsample(\n",
    "    features_train_valid, target_train_valid, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим DecisionTree, о прежде посмотрим на параметры уже обученной модели, чтобы их задать в новой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', max_depth=5, random_state=12345)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load(filename_decision_tree_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(class_weight='balanced', max_depth=5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', max_depth=5, random_state=12345)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train_valid, target_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = 0.5828377230246389\n",
      "roc_auc_score = 0.8449707752248262\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(features_test)\n",
    "probabilities_one_valid = model.predict_proba(features_test)[:,1]\n",
    "print('f1_score =',f1_score(target_test, predict_test))\n",
    "print('roc_auc_score =',roc_auc_score(target_test, probabilities_one_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на важность факторов для нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "importances = model.feature_importances_\n",
    "feature_names = [f'{i}' for i in features_test.columns]\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")данных\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика получилась лучше после обьединения данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=20, random_state=12345)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load(filename_random_forest_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=17, random_state=12345)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_upsampled_train_valid, target_upsampled_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score = 0.5822784810126582\n",
      "roc_auc_score = 0.8352409263781516\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(features_test)\n",
    "probabilities_one_valid = model.predict_proba(features_test)[:,1]\n",
    "print('f1_score =',f1_score(target_test, predict_test))\n",
    "print('roc_auc_score =',roc_auc_score(target_test, probabilities_one_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на важность параметров модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "feature_names = [f'{i}' for i in features_test.columns]\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания стали чуть хуже нежели которые были получены в предыдущем пунке, также стоит отметить что в обеих случая метрики оказались равны, поэтому в данном случае обе модели оказались равноценны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Обе модели ведут себя одинаково 'в бою' и применение любой из них к тестовым данным равноценно. Также можно заметить значительную разницу в важности параметров для разных моделей, в случае RandomForest принимаются во внимание все параметры в отличие от DecisionTree, что скорее всего не может не скзаать на скорости работы самой модели\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
